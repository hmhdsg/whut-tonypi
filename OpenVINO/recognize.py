#!/usr/bin/python3
# coding=utf8
import sys
sys.path.append('/home/pi/TonyPi/')
import cv2
import time
import math
import threading
import numpy as np
import json
import queue
import os
import signal
import re
import subprocess
import grp
import pwd

# Ê£ÄÊü•‰∏≤Âè£ÊùÉÈôê
def check_serial_permissions():
    """Ê£ÄÊü•‰∏≤Âè£ÊùÉÈôêÂíåÁî®Êà∑ÁªÑ"""
    try:
        current_user = pwd.getpwuid(os.getuid()).pw_name
        user_groups = [grp.getgrgid(g).gr_name for g in os.getgroups()]
        
        print(f"üìã ÂΩìÂâçÁî®Êà∑: {current_user}")
        print(f"üìã Áî®Êà∑ÁªÑ: {', '.join(user_groups)}")
        
        if 'dialout' in user_groups:
            print("‚úÖ Áî®Êà∑Âú®dialoutÁªÑ")
        else:
            print("‚ùå Áî®Êà∑‰∏çÂú®dialoutÁªÑ")
            print("üîß ËØ∑ÊâßË°å: sudo usermod -a -G dialout pi")
            
        if os.path.exists('/dev/ttyAMA0'):
            stat_info = os.stat('/dev/ttyAMA0')
            print(f"üìã /dev/ttyAMA0 ÊùÉÈôê: {oct(stat_info.st_mode)[-3:]}")
        else:
            print("‚ùå /dev/ttyAMA0 ‰∏çÂ≠òÂú®")
            
    except Exception as e:
        print(f"‚ùå ÊùÉÈôêÊ£ÄÊü•Â§±Ë¥•: {e}")

# Á≥ªÁªüËØäÊñ≠
print("üîç === TonyPiÂÆåÊï¥ÂäüËÉΩÁ≥ªÁªüËØäÊñ≠ ===")
check_serial_permissions()
print("========================\n")

# ÂØºÂÖ•VoskÁõ∏ÂÖ≥Ê®°Âùó
try:
    import vosk
    import pyaudio
    VOSK_AVAILABLE = True
    print("‚úÖ VoskËØ≠Èü≥ËØÜÂà´Ê®°ÂùóÂØºÂÖ•ÊàêÂäü")
except Exception as e:
    print(f"‚ùå VoskÊ®°ÂùóÂØºÂÖ•Â§±Ë¥•: {e}")
    VOSK_AVAILABLE = False

# ÂØºÂÖ•TonyPiÊ®°Âùó
try:
    import hiwonder.TTS as TTS
    TTS_AVAILABLE = True
    print("‚úÖ TTSËØ≠Èü≥ÂêàÊàêÊ®°ÂùóÂØºÂÖ•ÊàêÂäü")
except Exception as e:
    print(f"‚ùå TTSÊ®°ÂùóÂØºÂÖ•Â§±Ë¥•: {e}")
    TTS_AVAILABLE = False

try:
    import hiwonder.ASR as ASR
    ASR_AVAILABLE = True
    print("‚úÖ ASRËØ≠Èü≥ËØÜÂà´Ê®°ÂùóÂØºÂÖ•ÊàêÂäü")
except Exception as e:
    print(f"‚ùå ASRÊ®°ÂùóÂØºÂÖ•Â§±Ë¥•: {e}")
    ASR_AVAILABLE = False

try:
    import hiwonder.Camera as Camera
    import hiwonder.Misc as Misc
    from hiwonder import yaml_handle
    CAMERA_AVAILABLE = True
    print("‚úÖ ÊëÑÂÉèÂ§¥Ê®°ÂùóÂØºÂÖ•ÊàêÂäü")
except Exception as e:
    print(f"‚ùå ÊëÑÂÉèÂ§¥Ê®°ÂùóÂØºÂÖ•Â§±Ë¥•: {e}")
    CAMERA_AVAILABLE = False

# Âä®‰ΩúÊéßÂà∂Ê®°ÂùóÂØºÂÖ•
ACTION_CONTROL_AVAILABLE = False
AGC_AVAILABLE = False
BOARD_AVAILABLE = False

try:
    print("üîÑ Â∞ùËØïÂØºÂÖ•Âä®‰ΩúÊéßÂà∂Ê®°Âùó...")
    
    if os.path.exists('/dev/ttyAMA0'):
        import hiwonder.ActionGroupControl as AGC
        AGC_AVAILABLE = True
        print("‚úÖ ActionGroupControlÊ®°ÂùóÂØºÂÖ•ÊàêÂäü")
        
        import hiwonder.Board as Board
        BOARD_AVAILABLE = True
        print("‚úÖ BoardÊ®°ÂùóÂØºÂÖ•ÊàêÂäü")
        
        try:
            Board.setBuzzer(0)
            print("‚úÖ Á°¨‰ª∂ÈÄö‰ø°ÊµãËØïÊàêÂäü")
            ACTION_CONTROL_AVAILABLE = True
        except Exception as e:
            print(f"‚ö†Ô∏è  Á°¨‰ª∂ÈÄö‰ø°ÊµãËØïÂ§±Ë¥•: {e}")
    else:
        print("‚ùå ‰∏≤Âè£ËÆæÂ§á‰∏çÂ≠òÂú®")
        
except Exception as e:
    print(f"‚ùå Âä®‰ΩúÊéßÂà∂Ê®°ÂùóÂØºÂÖ•Â§±Ë¥•: {e}")

# Ê®°ÊãüÂä®‰ΩúÊéßÂà∂Á±ª
class MockActionControl:
    @staticmethod
    def runActionGroup(action_name, times=1, lock_servos='', with_stand=False):
        print(f"üé≠ [Ê®°Êãü] ÊâßË°åÂä®‰Ωú: {action_name}, Ê¨°Êï∞: {times}")
        time.sleep(0.2)
        return True

class MockBoard:
    @staticmethod
    def setPWMServoPulse(servo_id, pulse, time_ms):
        print(f"üé≠ [Ê®°Êãü] ËÆæÁΩÆËàµÊú∫ {servo_id}: {pulse}, Êó∂Èó¥: {time_ms}ms")
        return True
    
    @staticmethod
    def setBuzzer(state):
        print(f"üé≠ [Ê®°Êãü] ËúÇÈ∏£Âô®: {'ÂºÄ' if state else 'ÂÖ≥'}")
        return True

# Êô∫ËÉΩÊ®°ÂºèÈÄâÊã©
if not ACTION_CONTROL_AVAILABLE:
    print("üé≠ ÂêØÁî®Ê®°ÊãüÂä®‰ΩúÊéßÂà∂Ê®°Âºè")
    if not AGC_AVAILABLE:
        AGC = MockActionControl()
    if not BOARD_AVAILABLE:
        Board = MockBoard()
    ACTION_CONTROL_AVAILABLE = True

# ÂØºÂÖ•AprilTagÊ£ÄÊµã
try:
    import hiwonder.apriltag as apriltag
    APRILTAG_AVAILABLE = True
    print("‚úÖ AprilTagÊ®°ÂùóÂØºÂÖ•ÊàêÂäü")
except Exception as e:
    print(f"‚ùå AprilTagÊ®°ÂùóÂØºÂÖ•Â§±Ë¥•: {e}")
    APRILTAG_AVAILABLE = False

# ÊëÑÂÉèÂ§¥Ê†áÂÆöÁõ∏ÂÖ≥
try:
    if __name__ == '__main__':
        from CameraCalibration.CalibrationConfig import *
    else:
        from Functions.CameraCalibration.CalibrationConfig import *
    
    # Âä†ËΩΩÊ†áÂÆöÂèÇÊï∞
    param_data = np.load(calibration_param_path + '.npz')
    mtx = param_data['mtx_array']
    dist = param_data['dist_array']
    newcameramtx, roi = cv2.getOptimalNewCameraMatrix(mtx, dist, (640, 480), 0, (640, 480))
    mapx, mapy = cv2.initUndistortRectifyMap(mtx, dist, None, newcameramtx, (640, 480), 5)
    CALIBRATION_AVAILABLE = True
    print("‚úÖ ÊëÑÂÉèÂ§¥Ê†áÂÆöÂèÇÊï∞Âä†ËΩΩÊàêÂäü")
except Exception as e:
    print(f"‚ùå ÊëÑÂÉèÂ§¥Ê†áÂÆöÂèÇÊï∞Âä†ËΩΩÂ§±Ë¥•: {e}")
    CALIBRATION_AVAILABLE = False

class TimeoutHandler:
    """Ë∂ÖÊó∂Â§ÑÁêÜÂô®"""
    
    def __init__(self, timeout_seconds):
        self.timeout_seconds = timeout_seconds
        self.timed_out = False
    
    def timeout_handler(self, signum, frame):
        self.timed_out = True
        raise TimeoutError(f"Êìç‰ΩúË∂ÖÊó∂ ({self.timeout_seconds}Áßí)")
    
    def __enter__(self):
        self.timed_out = False
        signal.signal(signal.SIGALRM, self.timeout_handler)
        signal.alarm(self.timeout_seconds)
        return self
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        signal.alarm(0)
        return False

class SimpleColorDetector:
    """ÁÆÄÂçïÁöÑÈ¢úËâ≤Ê£ÄÊµãÂô®ÔºàÂ¢ûÂº∫Êí≠Êä•ÂäüËÉΩÔºâ"""
    
    def __init__(self):
        self.color_ranges = {
            'red': [
                [(0, 50, 50), (10, 255, 255)],
                [(170, 50, 50), (180, 255, 255)]
            ],
            'green': [[(40, 50, 50), (80, 255, 255)]],
            'blue': [[(100, 50, 50), (130, 255, 255)]],
            'yellow': [[(20, 50, 50), (40, 255, 255)]],
        }
        
        self.color_names_chinese = {
            'red': 'Á∫¢Ëâ≤',
            'green': 'ÁªøËâ≤', 
            'blue': 'ËìùËâ≤',
            'yellow': 'ÈªÑËâ≤'
        }
        
        self.current_target_color = 'red'
        self.detection_count = 0
        self.total_frames = 0
        self.last_announce_time = 0
        self.announce_interval = 3.0
        self.voice_callback = None
        
    def set_voice_callback(self, callback):
        """ËÆæÁΩÆËØ≠Èü≥Êí≠Êä•ÂõûË∞ÉÂáΩÊï∞"""
        self.voice_callback = callback
        
    def set_target_color(self, color):
        if color.lower() in self.color_ranges:
            self.current_target_color = color.lower()
            self.detection_count = 0
            self.last_announce_time = 0
            print(f"üéØ ËÆæÁΩÆÁõÆÊ†áÈ¢úËâ≤: {color}")
            return True
        return False
    
    def detect_color(self, frame):
        if frame is None:
            return None
            
        self.total_frames += 1
        
        try:
            hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)
            
            masks = []
            for color_range in self.color_ranges[self.current_target_color]:
                lower, upper = color_range
                mask = cv2.inRange(hsv, np.array(lower), np.array(upper))
                masks.append(mask)
            
            final_mask = masks[0]
            for mask in masks[1:]:
                final_mask = cv2.bitwise_or(final_mask, mask)
            
            kernel = np.ones((5,5), np.uint8)
            final_mask = cv2.morphologyEx(final_mask, cv2.MORPH_OPEN, kernel)
            final_mask = cv2.morphologyEx(final_mask, cv2.MORPH_CLOSE, kernel)
            
            contours, _ = cv2.findContours(final_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            
            result_frame = frame.copy()
            detected = False
            largest_area = 0
            
            for contour in contours:
                area = cv2.contourArea(contour)
                if area > 500:
                    cv2.drawContours(result_frame, [contour], -1, (0, 255, 0), 2)
                    x, y, w, h = cv2.boundingRect(contour)
                    cv2.rectangle(result_frame, (x, y), (x+w, y+h), (255, 0, 0), 2)
                    cv2.putText(result_frame, f'{self.current_target_color.upper()}', 
                               (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
                    detected = True
                    if area > largest_area:
                        largest_area = area
            
            cv2.putText(result_frame, f'Target: {self.current_target_color.upper()}', 
                       (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)
            cv2.putText(result_frame, f'Frame: {self.total_frames}', 
                       (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 1)
            
            if detected:
                self.detection_count += 1
                cv2.putText(result_frame, f'DETECTED! Area: {int(largest_area)}', 
                           (10, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)
                
                current_time = time.time()
                if current_time - self.last_announce_time >= self.announce_interval:
                    color_chinese = self.color_names_chinese.get(self.current_target_color, self.current_target_color)
                    announce_text = f"ËØÜÂà´Âà∞{color_chinese}"
                    print(f"üîä È¢úËâ≤Ê£ÄÊµãËØ≠Èü≥Êí≠Êä•: {announce_text}")
                    if self.voice_callback:
                        try:
                            self.voice_callback(announce_text)
                        except Exception as e:
                            print(f"‚ùå È¢úËâ≤Ê£ÄÊµãËØ≠Èü≥Êí≠Êä•Â§±Ë¥•: {e}")
                    self.last_announce_time = current_time
                    
                if self.detection_count % 10 == 1:
                    print(f"üéØ Ê£ÄÊµãÂà∞{self.current_target_color}È¢úËâ≤! Âå∫Âüü: {largest_area}")
            else:
                cv2.putText(result_frame, 'NOT DETECTED', 
                           (10, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)
            
            return result_frame
            
        except Exception as e:
            print(f"‚ùå È¢úËâ≤Ê£ÄÊµãÈîôËØØ: {e}")
            return frame

class OriginalFaceDetector:
    """ÂÆåÂÖ®ÊåâÁÖßÂéüÂßã‰ª£Á†ÅÈÄªËæëÁöÑ‰∫∫ËÑ∏Ê£ÄÊµãÂô®"""
    
    def __init__(self):
        # === ÂÆåÂÖ®Â§çÂà∂ÂéüÂßã‰ª£Á†ÅÁöÑÂèòÈáè ===
        self.__isRunning = False              # ‰∏ªË¶ÅËøêË°åÁä∂ÊÄÅ
        self.start_greet = False              # Ëß¶ÂèëÂä®‰ΩúÁöÑ‰ø°Âè∑
        self.action_finish = True             # Âä®‰ΩúÂÆåÊàêÊ†áÂøó
        self.last_action_time = 0             # ‰∏äÊ¨°Âä®‰ΩúÊó∂Èó¥
        self.action_interval = 3.0            # Âä®‰ΩúÈó¥Èöî
        
        # Ê£ÄÊµãÂô®ËÆæÁΩÆ
        self.conf_threshold = 0.6
        self.detection_count = 0
        self.total_frames = 0
        self.voice_callback = None
        
        # ËàµÊú∫ÈÖçÁΩÆ
        self.servo_data = None
        self.servo2_pulse = 1500
        self.d_pulse = 10
        self.load_servo_config()
        
        # ÂàùÂßãÂåñDNNÊ£ÄÊµãÂô®
        self.dnn_available = False
        self.opencv_available = False
        self.init_detectors()
        
        # ÂêØÂä®Âä®‰ΩúÊéßÂà∂Á∫øÁ®ãÔºàÂÆåÂÖ®ÊåâÁÖßÂéüÂßã‰ª£Á†ÅÔºâ
        self.control_thread = threading.Thread(target=self.move_control_loop)
        self.control_thread.daemon = True
        self.control_thread.start()
        print("‚úÖ ‰∫∫ËÑ∏Ê£ÄÊµãÂô®Âä®‰ΩúÊéßÂà∂Á∫øÁ®ãÂ∑≤ÂêØÂä®")
        
    def load_servo_config(self):
        """Âä†ËΩΩËàµÊú∫ÈÖçÁΩÆ"""
        try:
            if yaml_handle:
                self.servo_data = yaml_handle.get_yaml_data(yaml_handle.servo_file_path)
                self.servo2_pulse = self.servo_data.get('servo2', 1500)
                print(f"‚úÖ ËàµÊú∫ÈÖçÁΩÆÂä†ËΩΩÊàêÂäü: servo2={self.servo2_pulse}")
        except Exception as e:
            print(f"‚ùå ËàµÊú∫ÈÖçÁΩÆÂä†ËΩΩÂ§±Ë¥•: {e}")
            self.servo2_pulse = 1500
    
    def init_detectors(self):
        """ÂàùÂßãÂåñÊ£ÄÊµãÂô®"""
        # OpenCV‰∫∫ËÑ∏Ê£ÄÊµãÂô®
        try:
            self.face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
            self.opencv_available = True
            print("‚úÖ OpenCV‰∫∫ËÑ∏Ê£ÄÊµãÂô®Âä†ËΩΩÊàêÂäü")
        except Exception as e:
            print(f"‚ùå OpenCV‰∫∫ËÑ∏Ê£ÄÊµãÂô®Âä†ËΩΩÂ§±Ë¥•: {e}")
        
        # DNN‰∫∫ËÑ∏Ê£ÄÊµãÂô®
        try:
            modelFile = "/home/pi/TonyPi/models/res10_300x300_ssd_iter_140000_fp16.caffemodel"
            configFile = "/home/pi/TonyPi/models/deploy.prototxt"
            if os.path.exists(modelFile) and os.path.exists(configFile):
                self.net = cv2.dnn.readNetFromCaffe(configFile, modelFile)
                self.dnn_available = True
                print("‚úÖ DNN‰∫∫ËÑ∏Ê£ÄÊµãÂô®Âä†ËΩΩÊàêÂäü")
            else:
                print("‚ùå DNNÊ®°ÂûãÊñá‰ª∂‰∏çÂ≠òÂú®")
        except Exception as e:
            print(f"‚ùå DNN‰∫∫ËÑ∏Ê£ÄÊµãÂô®Âä†ËΩΩÂ§±Ë¥•: {e}")
    
    def set_voice_callback(self, callback):
        """ËÆæÁΩÆËØ≠Èü≥Êí≠Êä•ÂõûË∞ÉÂáΩÊï∞"""
        self.voice_callback = callback
    
    def start_detection(self):
        """ÂêØÂä®Ê£ÄÊµãÔºàÂéüÂßã‰ª£Á†ÅÈ£éÊ†ºÔºâ"""
        print("üë§ === ÂêØÂä®‰∫∫ËÑ∏Ê£ÄÊµã ===")
        self.__isRunning = True
        self.detection_count = 0
        self.total_frames = 0
        self.action_finish = True
        self.start_greet = False
        
        # ÂàùÂßãÂåñËàµÊú∫‰ΩçÁΩÆ
        if ACTION_CONTROL_AVAILABLE:
            try:
                print("üîÑ ÂàùÂßãÂåñËàµÊú∫‰ΩçÁΩÆ...")
                Board.setPWMServoPulse(1, 1800, 500)
                Board.setPWMServoPulse(2, self.servo2_pulse, 500)
                print("‚úÖ ËàµÊú∫ÂàùÂßãÂåñÂÆåÊàê")
            except Exception as e:
                print(f"‚ùå ËàµÊú∫ÂàùÂßãÂåñÂ§±Ë¥•: {e}")
        
    def stop_detection(self):
        """ÂÅúÊ≠¢Ê£ÄÊµãÔºàÂéüÂßã‰ª£Á†ÅÈ£éÊ†ºÔºâ"""
        print("üë§ === ÂÅúÊ≠¢‰∫∫ËÑ∏Ê£ÄÊµã ===")
        self.__isRunning = False
        self.start_greet = False
    
    def move_control_loop(self):
        """Âä®‰ΩúÊéßÂà∂Á∫øÁ®ãÔºàÂÆåÂÖ®ÊåâÁÖßÂéüÂßã‰ª£Á†ÅÔºâ"""
        while True:
            try:
                # Âè™Âú®ËøêË°åÁä∂ÊÄÅ‰∏ãÊ£ÄÊü•‰ø°Âè∑
                if self.__isRunning:
                    if self.start_greet:
                        print("ü§ñ === Ê£ÄÊµãÂà∞start_greet‰ø°Âè∑ÔºåÂºÄÂßãÊâßË°åÂä®‰Ωú ===")
                        
                        # ÈáçÁΩÆ‰ø°Âè∑
                        self.start_greet = False
                        
                        # ËÆæÁΩÆÂä®‰ΩúÁä∂ÊÄÅ‰∏∫ÊâßË°å‰∏≠
                        self.action_finish = False
                        
                        try:
                            # ËØ≠Èü≥Êí≠Êä•"ËØÜÂà´Âà∞‰∫∫ËÑ∏"
                            if self.voice_callback:
                                print("üîä ÂºÄÂßãËØ≠Èü≥Êí≠Êä•...")
                                self.voice_callback("ËØÜÂà´Âà∞‰∫∫ËÑ∏")
                                print("üîä ‚úÖ ËØ≠Èü≥Êí≠Êä•ÂÆåÊàê")
                            
                            # ÊâßË°åÊå•ÊâãÂä®‰Ωú
                            if ACTION_CONTROL_AVAILABLE:
                                print("ü§ñ ÊâßË°åÊå•ÊâãÂä®‰Ωú...")
                                AGC.runActionGroup('wave')
                                print("ü§ñ ‚úÖ Êå•ÊâãÂä®‰ΩúÊâßË°åÂÆåÊàê")
                                
                            # ËÆ∞ÂΩïÊó∂Èó¥
                            self.last_action_time = time.time()
                            
                        except Exception as e:
                            print(f"‚ùå Âä®‰ΩúÊâßË°åÂ§±Ë¥•: {e}")
                        finally:
                            # ËÆæÁΩÆÂä®‰ΩúÂÆåÊàê
                            self.action_finish = True
                            print("‚úÖ Âä®‰ΩúÊµÅÁ®ãÂÆåÊàê")
                
                time.sleep(0.01)  # ÈÅøÂÖçCPUÂç†Áî®ËøáÈ´ò
                
            except Exception as e:
                print(f"‚ùå Âä®‰ΩúÊéßÂà∂Á∫øÁ®ãÈîôËØØ: {e}")
                time.sleep(0.1)
    
    def detect_faces_dnn(self, frame):
        """‰ΩøÁî®DNNÊ£ÄÊµã‰∫∫ËÑ∏ÔºàÂéüÂßã‰ª£Á†ÅÈÄªËæëÔºâ"""
        if not self.dnn_available:
            return frame, 0
            
        try:
            img_h, img_w = frame.shape[:2]
            blob = cv2.dnn.blobFromImage(frame, 1, (150, 150), [104, 117, 123], False, False)
            self.net.setInput(blob)
            detections = self.net.forward()
            
            face_count = 0
            result_frame = frame.copy()
            
            for i in range(detections.shape[2]):
                confidence = detections[0, 0, i, 2]
                if confidence > self.conf_threshold:
                    x1 = int(detections[0, 0, i, 3] * img_w)
                    y1 = int(detections[0, 0, i, 4] * img_h)
                    x2 = int(detections[0, 0, i, 5] * img_w)
                    y2 = int(detections[0, 0, i, 6] * img_h)
                    
                    face_count += 1
                    
                    # ÁªòÂà∂‰∫∫ËÑ∏Ê°Ü
                    cv2.rectangle(result_frame, (x1, y1), (x2, y2), (0, 255, 0), 2)
                    cv2.putText(result_frame, f'FACE {confidence:.2f}', (x1, y1-10), 
                               cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)
                    
                    # ËÆ°ÁÆó‰∫∫ËÑ∏‰∏≠ÂøÉ
                    face_center_x = (x1 + x2) / 2
                    face_center_y = (y1 + y2) / 2
                    img_center_x = img_w / 2
                    img_center_y = img_h / 2
                    
                    # ÁªòÂà∂‰∏≠ÂøÉÁÇπ
                    cv2.circle(result_frame, (int(face_center_x), int(face_center_y)), 5, (255, 0, 0), -1)
                    cv2.circle(result_frame, (int(img_center_x), int(img_center_y)), 5, (0, 0, 255), -1)
                    
                    # ËÆ°ÁÆóË∑ùÁ¶ª
                    center_distance = abs(face_center_x - img_center_x)
                    center_threshold = img_w / 4
                    
                    # === ÂéüÂßã‰ª£Á†ÅÁöÑÊ†∏ÂøÉÊ£ÄÊµãÈÄªËæë ===
                    if center_distance < center_threshold:
                        cv2.putText(result_frame, 'CENTER!', (x1, y2+25), 
                                   cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)
                        
                        # Ê£ÄÊü•Âä®‰ΩúÊù°‰ª∂ÔºàÂéüÂßãÈÄªËæëÔºâ
                        current_time = time.time()
                        time_diff = current_time - self.last_action_time
                        
                        if self.action_finish and time_diff >= self.action_interval:
                            self.start_greet = True  # === ÂÖ≥ÈîÆ‰ø°Âè∑ ===
                    else:
                        cv2.putText(result_frame, 'OFF CENTER', (x1, y2+25), 
                                   cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)
                    
                    # ÊòæÁ§∫Ë∑ùÁ¶ª‰ø°ÊÅØ
                    cv2.putText(result_frame, f'Dist: {center_distance:.0f}', (x1, y2+50), 
                               cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 0), 2)
            
            return result_frame, face_count
            
        except Exception as e:
            print(f"‚ùå DNN‰∫∫ËÑ∏Ê£ÄÊµãÈîôËØØ: {e}")
            return frame, 0
    
    def detect_faces(self, frame):
        """‰∏ªÊ£ÄÊµãÂáΩÊï∞"""
        if frame is None or not self.__isRunning:
            return frame
            
        self.total_frames += 1
        
        # ‰ºòÂÖà‰ΩøÁî®DNNÊ£ÄÊµãÂô®
        if self.dnn_available:
            result_frame, face_count = self.detect_faces_dnn(frame)
        else:
            return frame
        
        # Ê∑ªÂä†Áä∂ÊÄÅ‰ø°ÊÅØ
        cv2.putText(result_frame, f'Faces: {face_count}', (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
        cv2.putText(result_frame, f'Frame: {self.total_frames}', (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)
        cv2.putText(result_frame, f'Running: {self.__isRunning}', (10, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)
        cv2.putText(result_frame, f'Action: {"Ready" if self.action_finish else "Working"}', (10, 120), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)
        
        if face_count > 0:
            self.detection_count += 1
        
        return result_frame
    
    def test_action(self):
        """ÊµãËØïÂä®‰ΩúÔºàÁõ¥Êé•Ëß¶ÂèëÔºâ"""
        print("üß™ === ÊµãËØï‰∫∫ËÑ∏Âä®‰Ωú ===")
        if not self.__isRunning:
            self.__isRunning = True
        
        self.start_greet = True
        time.sleep(0.5)

# AprilTagÊ£ÄÊµãÂô®Á±ª
class AprilTagDetector:
    """AprilTagÊ£ÄÊµãÂô®"""
    
    def __init__(self):
        self.detector = None
        self.available = False
        self.detection_count = 0
        self.total_frames = 0
        self.voice_callback = None
        self.current_tag_id = None
        
        if APRILTAG_AVAILABLE:
            try:
                self.detector = apriltag.Detector(searchpath=apriltag._get_demo_searchpath())
                self.available = True
                print("‚úÖ AprilTagÊ£ÄÊµãÂô®ÂàùÂßãÂåñÊàêÂäü")
            except Exception as e:
                print(f"‚ùå AprilTagÊ£ÄÊµãÂô®ÂàùÂßãÂåñÂ§±Ë¥•: {e}")
            
        # Âä®‰ΩúÊò†Â∞Ñ
        self.action_map = {
            1: ('wave', 'Êå•Êâã'),
            2: ('stepping', 'ÂéüÂú∞Ë∏èÊ≠•'),
            3: ('twist', 'Êâ≠ËÖ∞')
        }
        
    def set_voice_callback(self, callback):
        """ËÆæÁΩÆËØ≠Èü≥Êí≠Êä•ÂõûË∞ÉÂáΩÊï∞"""
        self.voice_callback = callback
    
    def detect_apriltag(self, img):
        """Ê£ÄÊµãAprilTag"""
        if not self.available or img is None:
            return None, None
            
        try:
            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
            detections = self.detector.detect(gray, return_image=False)
            
            if len(detections) != 0:
                for detection in detections:
                    corners = np.rint(detection.corners)
                    cv2.drawContours(img, [np.array(corners, np.int)], -1, (0, 255, 255), 2)
                    tag_family = str(detection.tag_family, encoding='utf-8')
                    tag_id = int(detection.tag_id)
                    
                    return tag_family, tag_id
                    
            return None, None
            
        except Exception as e:
            print(f"‚ùå AprilTagÊ£ÄÊµãÈîôËØØ: {e}")
            return None, None
    
    def detect_tags(self, frame):
        """‰∏ªÊ†áÁ≠æÊ£ÄÊµãÂáΩÊï∞"""
        if frame is None:
            return frame
            
        self.total_frames += 1
        result_frame = frame.copy()
        
        tag_family, tag_id = self.detect_apriltag(result_frame)
        
        if tag_id is not None:
            cv2.putText(result_frame, f"tag_id: {tag_id}", (10, result_frame.shape[0] - 30), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.65, [0, 0, 255], 2)
            cv2.putText(result_frame, f"tag_family: {tag_family}", (10, result_frame.shape[0] - 10), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.65, [0, 0, 255], 2)
            
            # ËÆæÁΩÆÂΩìÂâçÊ†áÁ≠æID
            if self.current_tag_id != tag_id:
                self.current_tag_id = tag_id
                
                # ÊâßË°åÂØπÂ∫îÂä®‰Ωú
                if tag_id in self.action_map:
                    action_name, action_chinese = self.action_map[tag_id]
                    
                    if ACTION_CONTROL_AVAILABLE:
                        try:
                            print(f"ü§ñ ÊâßË°åÂä®‰Ωú: {action_chinese} (ID: {tag_id})")
                            AGC.runActionGroup(action_name)
                            
                            # ËØ≠Èü≥Êí≠Êä•
                            if self.voice_callback:
                                announce_text = f"ËØÜÂà´Âà∞Ê†áÁ≠æ{tag_id}ÔºåÊâßË°å{action_chinese}"
                                try:
                                    self.voice_callback(announce_text)
                                except Exception as e:
                                    print(f"‚ùå Ê†áÁ≠æÊ£ÄÊµãËØ≠Èü≥Êí≠Êä•Â§±Ë¥•: {e}")
                            
                        except Exception as e:
                            print(f"‚ùå Âä®‰ΩúÊâßË°åÂ§±Ë¥•: {e}")
                    
                self.detection_count += 1
                
        else:
            cv2.putText(result_frame, "tag_id: None", (10, result_frame.shape[0] - 30), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.65, [0, 0, 255], 2)
            self.current_tag_id = None
        
        # Ê∑ªÂä†Áä∂ÊÄÅ‰ø°ÊÅØ
        cv2.putText(result_frame, f'Tags: {1 if tag_id else 0}', 
                   (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)
        cv2.putText(result_frame, f'Frame: {self.total_frames}', 
                   (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 1)
        
        return result_frame

class TransportSystem:
    """Êê¨ËøêÁ≥ªÁªü"""
    
    def __init__(self, voice_callback=None):
        print("üöõ ÂàùÂßãÂåñÊê¨ËøêÁ≥ªÁªü...")
        self.voice_callback = voice_callback
        
        # Âü∫Á°ÄÈÖçÁΩÆ
        self.lab_data = None
        self.servo_data = None
        self.load_config()
        
        # Êê¨ËøêÂä®‰ΩúÁªÑÂêçÁß∞
        self.go_forward = 'go_forward'
        self.back = 'back_fast'
        self.turn_left = 'turn_left_small_step'
        self.turn_right = 'turn_right_small_step'
        self.left_move = 'left_move'
        self.right_move = 'right_move'
        self.left_move_large = 'left_move_30'
        self.right_move_large = 'right_move_30'
        
        # È¢úËâ≤ÂØπÂ∫îÁöÑtagÁºñÂè∑
        self.color_tag = {'red': 1, 'green': 2, 'blue': 3}
        self.color_names_chinese = {'red': 'Á∫¢Ëâ≤', 'green': 'ÁªøËâ≤', 'blue': 'ËìùËâ≤'}
        
        # ËàµÊú∫ÈîÅÂÆöÈÖçÁΩÆ
        self.LOCK_SERVOS = {'6': 650, '7': 850, '8': 0, '14': 350, '15': 150, '16': 1000}
        
        # Á≥ªÁªüÁä∂ÊÄÅ
        self.is_running = False
        self.current_object_color = None
        
        # Êê¨ËøêÁä∂ÊÄÅÂèòÈáè
        self.reset_transport_vars()
        
        # ÂàùÂßãÂåñAprilTagÊ£ÄÊµãÂô®
        if APRILTAG_AVAILABLE:
            try:
                self.detector = apriltag.Detector(searchpath=apriltag._get_demo_searchpath())
                print("‚úÖ Êê¨ËøêÁ≥ªÁªüAprilTagÊ£ÄÊµãÂô®ÂàùÂßãÂåñÊàêÂäü")
            except Exception as e:
                print(f"‚ùå Êê¨ËøêÁ≥ªÁªüAprilTagÊ£ÄÊµãÂô®ÂàùÂßãÂåñÂ§±Ë¥•: {e}")
                self.detector = None
        else:
            self.detector = None
        
        # ÂêØÂä®Âä®‰ΩúÊéßÂà∂Á∫øÁ®ã
        self.action_thread = threading.Thread(target=self.action_control_loop)
        self.action_thread.daemon = True
        self.action_thread.start()
        
        print("‚úÖ Êê¨ËøêÁ≥ªÁªüÂàùÂßãÂåñÂÆåÊàê")
    
    def load_config(self):
        """Âä†ËΩΩÈÖçÁΩÆÊñá‰ª∂"""
        try:
            if yaml_handle:
                self.lab_data = yaml_handle.get_yaml_data(yaml_handle.lab_file_path)
                self.servo_data = yaml_handle.get_yaml_data(yaml_handle.servo_file_path)
        except Exception as e:
            print(f"‚ùå Êê¨ËøêÁ≥ªÁªüÈÖçÁΩÆÊñá‰ª∂Âä†ËΩΩÂ§±Ë¥•: {e}")
            # ÈªòËÆ§ÈÖçÁΩÆ
            self.servo_data = {'servo1': 1500, 'servo2': 1500}
    
    def reset_transport_vars(self):
        """ÈáçÁΩÆÊê¨ËøêÁõ∏ÂÖ≥ÂèòÈáè"""
        self.d_x = 15
        self.d_y = 15
        self.step = 1
        self.time_start = 0
        self.x_dis = self.servo_data['servo2'] if self.servo_data else 1500
        self.y_dis = self.servo_data['servo1'] if self.servo_data else 1500
        self.start_count = True
        self.object_center_x, self.object_center_y, self.object_angle = -2, -2, 0
        self.turn = 'None'
        self.CENTER_X = 350
        self.find_box = True
        self.go_step = 3
        self.lock_servos = ''
        self.stop_detect = False
        self.haved_find_tag = False
        self.head_turn = 'left_right'
        self.color_center_x, self.color_center_y = -1, -1
    
    def get_area_max_contour(self, contours):
        """ÊâæÂá∫Èù¢ÁßØÊúÄÂ§ßÁöÑËΩÆÂªì"""
        contour_area_max = 0
        area_max_contour = None

        for c in contours:
            contour_area_temp = math.fabs(cv2.contourArea(c))
            if contour_area_temp > contour_area_max:
                contour_area_max = contour_area_temp
                if contour_area_temp >= 300:
                    area_max_contour = c

        return area_max_contour, contour_area_max
    
    def color_detect(self, img, target_color):
        """È¢úËâ≤Ê£ÄÊµã"""
        if not self.lab_data or target_color not in self.lab_data:
            return 'None', -1, -1, 0
        
        img_h, img_w = img.shape[:2]
        size = (320, 240)
        
        frame_resize = cv2.resize(img, size, interpolation=cv2.INTER_NEAREST)
        frame_gb = cv2.GaussianBlur(frame_resize, (3, 3), 3)   
        frame_lab = cv2.cvtColor(frame_gb, cv2.COLOR_BGR2LAB)
        
        # È¢úËâ≤ËåÉÂõ¥Ê£ÄÊµã
        frame_mask = cv2.inRange(frame_lab,
                                 (self.lab_data[target_color]['min'][0],
                                  self.lab_data[target_color]['min'][1],
                                  self.lab_data[target_color]['min'][2]),
                                 (self.lab_data[target_color]['max'][0],
                                  self.lab_data[target_color]['max'][1],
                                  self.lab_data[target_color]['max'][2]))
        
        eroded = cv2.erode(frame_mask, cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3)))
        dilated = cv2.dilate(eroded, cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3)))
        contours = cv2.findContours(dilated, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)[-2]
        
        area_max_contour, area_max = self.get_area_max_contour(contours)
        
        if area_max > 500:
            rect = cv2.minAreaRect(area_max_contour)
            angle = rect[2]
            
            box = np.int0(cv2.boxPoints(rect))
            for j in range(4):
                box[j, 0] = int(Misc.map(box[j, 0], 0, size[0], 0, img_w))
                box[j, 1] = int(Misc.map(box[j, 1], 0, size[1], 0, img_h))

            cv2.drawContours(img, [box], -1, (0, 255, 255), 2)
            
            pt1_x, pt1_y = box[0, 0], box[0, 1]
            pt3_x, pt3_y = box[2, 0], box[2, 1]            
            center_x, center_y = int((pt1_x + pt3_x) / 2), int((pt1_y + pt3_y) / 2)
            cv2.circle(img, (center_x, center_y), 5, (0, 255, 255), -1)
            
            return target_color, center_x, center_y, angle
                    
        return 'None', -1, -1, 0
    
    def apriltag_detect(self, img):
        """AprilTagÊ£ÄÊµã"""
        if not self.detector:
            return [-1, -1, 0], [-1, -1, 0], [-1, -1, 0]
        
        try:
            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
            detections = self.detector.detect(gray, return_image=False)
            
            tag_1 = [-1, -1, 0]
            tag_2 = [-1, -1, 0] 
            tag_3 = [-1, -1, 0]

            if len(detections) != 0:
                for detection in detections:                       
                    corners = np.rint(detection.corners)
                    cv2.drawContours(img, [np.array(corners, np.int)], -1, (0, 255, 255), 2)

                    tag_family = str(detection.tag_family, encoding='utf-8')
                    tag_id = str(detection.tag_id)

                    object_center_x, object_center_y = int(detection.center[0]), int(detection.center[1])
                    cv2.circle(img, (object_center_x, object_center_y), 5, (0, 255, 255), -1)
                    
                    object_angle = int(math.degrees(math.atan2(corners[0][1] - corners[1][1], corners[0][0] - corners[1][0])))
                    
                    if tag_family == 'tag36h11':
                        if tag_id == '1':
                            tag_1 = [object_center_x, object_center_y, object_angle]
                        elif tag_id == '2':
                            tag_2 = [object_center_x, object_center_y, object_angle]
                        elif tag_id == '3':
                            tag_3 = [object_center_x, object_center_y, object_angle]
            
            return tag_1, tag_2, tag_3
        except Exception as e:
            print(f"‚ùå Êê¨ËøêÁ≥ªÁªüAprilTagÊ£ÄÊµãÈîôËØØ: {e}")
            return [-1, -1, 0], [-1, -1, 0], [-1, -1, 0]
    
    def get_turn_direction(self, tag_id, tag_data):
        """ÈÄöËøáÂÖ∂‰ªñAprilTagÂà§Êñ≠ÁõÆÊ†áTag‰ΩçÁΩÆ"""
        tag_1, tag_2, tag_3 = tag_data
        
        if tag_id == 1:
            if tag_2[0] == -1:
                if tag_3[0] != -1:
                    return 'left'
            else:
                return 'left'
        elif tag_id == 2:
            if tag_1[0] == -1:
                if tag_3[0] != -1:
                    return 'left'
            else:
                return 'right'
        elif tag_id == 3:
            if tag_1[0] == -1:
                if tag_2[0] != -1:
                    return 'right'
            else:
                return 'right'
        
        return 'None'
    
    def action_control_loop(self):
        """Âä®‰ΩúÊéßÂà∂Á∫øÁ®ã"""
        while True:
            try:
                if self.is_running and self.current_object_color:
                    self.execute_transport_actions()
                else:
                    time.sleep(0.01)
            except Exception as e:
                print(f"‚ùå Êê¨ËøêÂä®‰ΩúÊéßÂà∂Á∫øÁ®ãÈîôËØØ: {e}")
                time.sleep(0.1)
    
    def execute_transport_actions(self):
        """ÊâßË°åÊê¨ËøêÂä®‰ΩúÈÄªËæëÔºàÂÆåÊï¥‰øùÁïôÂéüÂßãÈÄªËæëÔºâ"""
        if self.object_center_x == -3:  # ÂØªÊâæÊ†áÁ≠æ‰ΩÜÊâæÂà∞ÂÖ∂‰ªñÊ†áÁ≠æ
            if self.turn == 'left':
                AGC.runActionGroup(self.turn_left, lock_servos=self.lock_servos)
            elif self.turn == 'right':
                AGC.runActionGroup(self.turn_right, lock_servos=self.lock_servos)
                
        elif self.haved_find_tag and self.object_center_x == -1:
            if self.x_dis > self.servo_data['servo2']:                    
                AGC.runActionGroup(self.turn_left, lock_servos=self.lock_servos)
            elif self.x_dis < self.servo_data['servo2']:
                AGC.runActionGroup(self.turn_right, lock_servos=self.lock_servos)
            else:
                self.haved_find_tag = False
                
        elif self.object_center_x >= 0:
            self.handle_object_found()
            
        elif self.object_center_x == -1:
            self.search_for_object()
        
        time.sleep(0.01)
    
    def handle_object_found(self):
        """Â§ÑÁêÜÊâæÂà∞ÁõÆÊ†áÁâ©‰ΩìÁöÑÊÉÖÂÜµÔºàÂ¢ûÂº∫Â§¥ÈÉ®Ë∑üÈöèÂäüËÉΩÔºâ"""
        if not self.find_box:  # ÊîæÁΩÆÈò∂ÊÆµÈÅøÈöú
            if self.color_center_y > 350:
                if (self.color_center_x - self.CENTER_X) > 80:
                    AGC.runActionGroup(self.go_forward, lock_servos=self.lock_servos)
                elif (self.color_center_x > self.CENTER_X and self.object_center_x >= self.CENTER_X) or \
                     (self.color_center_x <= self.CENTER_X and self.object_center_x >= self.CENTER_X):
                    AGC.runActionGroup(self.right_move_large, lock_servos=self.lock_servos)
                elif (self.color_center_x > self.CENTER_X and self.object_center_x < self.CENTER_X) or \
                     (self.color_center_x <= self.CENTER_X and self.object_center_x < self.CENTER_X):
                    AGC.runActionGroup(self.left_move_large, lock_servos=self.lock_servos)

        # === Êñ∞Â¢ûÔºöÂÆûÊó∂Â§¥ÈÉ®Ë∑üÈöèÈÄªËæë ===
        self.update_head_tracking()

        # ËΩ¨Â§¥ÊâæÂà∞Áâ©‰ΩìÊó∂Â§¥Âõû‰∏≠
        if self.x_dis != self.servo_data['servo2'] and not self.haved_find_tag:
            self.head_turn = 'left_right'
            self.start_count = True
            self.d_x, self.d_y = 15, 15
            self.haved_find_tag = True
            
            Board.setPWMServoPulse(1, self.servo_data['servo1'], 500)
            Board.setPWMServoPulse(2, self.servo_data['servo2'], 500)
            time.sleep(0.6)
            
        elif self.step == 1:  # Â∑¶Âè≥Ë∞ÉÊï¥ÂØπ‰∏≠
            self.x_dis = self.servo_data['servo2']
            self.y_dis = self.servo_data['servo1']                   
            self.turn = ''
            self.haved_find_tag = False
            
            if (self.object_center_x - self.CENTER_X) > 170 and self.object_center_y > 330:
                AGC.runActionGroup(self.back, lock_servos=self.lock_servos)   
            elif self.object_center_x - self.CENTER_X > 80:
                AGC.runActionGroup(self.turn_right, lock_servos=self.lock_servos)
            elif self.object_center_x - self.CENTER_X < -80:
                AGC.runActionGroup(self.turn_left, lock_servos=self.lock_servos)                        
            elif 0 < self.object_center_y <= 250:
                AGC.runActionGroup(self.go_forward, lock_servos=self.lock_servos)
            else:
                self.step = 2
                
        elif self.step == 2:  # Êé•ËøëÁâ©‰Ωì
            if 330 < self.object_center_y:
                AGC.runActionGroup(self.back, lock_servos=self.lock_servos)
            elif self.find_box:  # Êê¨ËøêÈò∂ÊÆµ
                self.handle_pickup_approach()
            else:  # ÊîæÁΩÆÈò∂ÊÆµ
                self.handle_place_approach()
                
        elif self.step == 3:  # Á≤æÁªÜË∞ÉÊï¥
            self.handle_fine_adjustment()
            
        elif self.step == 4:  # ÊúÄÁªàÊé•Ëøë
            self.handle_final_approach()
            
        elif self.step == 5:  # ÊâßË°åÊãøËµ∑ÊàñÊîæ‰∏ã
            self.handle_pickup_or_place()
    
    def handle_pickup_approach(self):
        """Â§ÑÁêÜÊãæÂèñÈò∂ÊÆµÁöÑÊé•Ëøë"""
        if self.object_center_x - self.CENTER_X > 150:
            AGC.runActionGroup(self.right_move_large, lock_servos=self.lock_servos)
        elif self.object_center_x - self.CENTER_X < -150:
            AGC.runActionGroup(self.left_move_large, lock_servos=self.lock_servos)                        
        elif -10 > self.object_angle > -45:
            AGC.runActionGroup(self.turn_left, lock_servos=self.lock_servos)
        elif -80 < self.object_angle <= -45:
            AGC.runActionGroup(self.turn_right, lock_servos=self.lock_servos)
        elif self.object_center_x - self.CENTER_X > 40:
            AGC.runActionGroup(self.right_move_large, lock_servos=self.lock_servos)
        elif self.object_center_x - self.CENTER_X < -40:
            AGC.runActionGroup(self.left_move_large, lock_servos=self.lock_servos)
        else:
            self.step = 3
    
    def handle_place_approach(self):
        """Â§ÑÁêÜÊîæÁΩÆÈò∂ÊÆµÁöÑÊé•Ëøë"""
        if self.object_center_x - self.CENTER_X > 150:
            AGC.runActionGroup(self.right_move_large, lock_servos=self.lock_servos)
        elif self.object_center_x - self.CENTER_X < -150:
            AGC.runActionGroup(self.left_move_large, lock_servos=self.lock_servos)                        
        elif self.object_angle < -5:
            AGC.runActionGroup(self.turn_left, lock_servos=self.lock_servos)
        elif 5 < self.object_angle:
            AGC.runActionGroup(self.turn_right, lock_servos=self.lock_servos)
        elif self.object_center_x - self.CENTER_X > 40:
            AGC.runActionGroup(self.right_move_large, lock_servos=self.lock_servos)
        elif self.object_center_x - self.CENTER_X < -40:
            AGC.runActionGroup(self.left_move_large, lock_servos=self.lock_servos)
        else:
            self.step = 3
    
    def handle_fine_adjustment(self):
        """Â§ÑÁêÜÁ≤æÁªÜË∞ÉÊï¥"""
        if 340 < self.object_center_y:
            AGC.runActionGroup(self.back, lock_servos=self.lock_servos)
        elif 0 < self.object_center_y <= 250:
            AGC.runActionGroup(self.go_forward, lock_servos=self.lock_servos)
        elif self.object_center_x - self.CENTER_X >= 40:
            AGC.runActionGroup(self.right_move_large, lock_servos=self.lock_servos)
        elif self.object_center_x - self.CENTER_X <= -40:
            AGC.runActionGroup(self.left_move_large, lock_servos=self.lock_servos) 
        elif 20 <= self.object_center_x - self.CENTER_X < 40:
            AGC.runActionGroup(self.right_move, lock_servos=self.lock_servos)
        elif -40 < self.object_center_x - self.CENTER_X < -20:                      
            AGC.runActionGroup(self.left_move, lock_servos=self.lock_servos)
        else:
            self.step = 4
    
    def handle_final_approach(self):
        """Â§ÑÁêÜÊúÄÁªàÊé•Ëøë"""
        if 300 < self.object_center_y <= 340:
            AGC.runActionGroup('go_forward_one_step', lock_servos=self.lock_servos)
            time.sleep(0.2)
        elif 0 <= self.object_center_y <= 300:
            AGC.runActionGroup(self.go_forward, lock_servos=self.lock_servos)
        else:
            if self.object_center_y >= 370:
                self.go_step = 2
            else:
                self.go_step = 3
            if abs(self.object_center_x - self.CENTER_X) <= 20:
                self.stop_detect = True
                self.step = 5
            else:
                self.step = 3
    
    def handle_pickup_or_place(self):
        """Â§ÑÁêÜÊãæÂèñÊàñÊîæÁΩÆÂä®‰Ωú"""
        if self.find_box:  # ÊãæÂèñ
            AGC.runActionGroup('go_forward_one_step', times=3)
            AGC.runActionGroup('stand', lock_servos=self.lock_servos)
            AGC.runActionGroup('move_up')
            self.lock_servos = self.LOCK_SERVOS
            self.step = 6
            color_chinese = self.color_names_chinese.get(self.current_object_color, self.current_object_color)
            if self.voice_callback:
                self.voice_callback(f'Â∑≤ÊãæÂèñ{color_chinese}ÊñπÂùó')
        else:  # ÊîæÁΩÆ
            AGC.runActionGroup('go_forward_one_step', times=self.go_step, lock_servos=self.lock_servos)
            AGC.runActionGroup('stand', lock_servos=self.lock_servos)
            AGC.runActionGroup('put_down')
            AGC.runActionGroup(self.back, times=5, with_stand=True)
            color_chinese = self.color_names_chinese.get(self.current_object_color, self.current_object_color)
            if self.voice_callback:
                self.voice_callback(f'{color_chinese}ÊñπÂùóÊê¨ËøêÂÆåÊàê')
            self.lock_servos = ''
            self.step = 6
            self.current_object_color = None  # ÂÆåÊàê‰ªªÂä°
    
    def update_head_tracking(self):
        """ÂÆûÊó∂Â§¥ÈÉ®Ë∑üÈöèÁõÆÊ†áÁâ©‰Ωì"""
        if self.object_center_x == -1 or self.object_center_x == -2:
            return  # Ê≤°ÊúâÊ£ÄÊµãÂà∞ÁõÆÊ†áÔºå‰∏çË∞ÉÊï¥Â§¥ÈÉ®
        
        # Ëé∑ÂèñÂõæÂÉè‰∏≠ÂøÉÂíåÁõÆÊ†á‰ΩçÁΩÆ
        img_center_x = 320  # ÂÅáËÆæÂõæÂÉèÂÆΩÂ∫¶640Ôºå‰∏≠ÂøÉ‰∏∫320
        target_x = self.object_center_x
        target_y = self.object_center_y
        
        # ËÆ°ÁÆóÂÅèÂ∑Æ
        error_x = target_x - img_center_x
        error_y = target_y - 240  # ÂÅáËÆæÂõæÂÉèÈ´òÂ∫¶480Ôºå‰∏≠ÂøÉ‰∏∫240
        
        # Â§¥ÈÉ®Ë∑üÈöèÈòàÂÄº
        follow_threshold_x = 50  # Ê∞¥Âπ≥Ë∑üÈöèÈòàÂÄº
        follow_threshold_y = 40  # ÂûÇÁõ¥Ë∑üÈöèÈòàÂÄº
        
        # ËàµÊú∫Ë∞ÉÊï¥Ê≠•Èïø
        servo_step_x = 3  # Ê∞¥Âπ≥Ë∞ÉÊï¥Ê≠•Èïø
        servo_step_y = 3  # ÂûÇÁõ¥Ë∞ÉÊï¥Ê≠•Èïø
        
        # ËàµÊú∫ÈôêÂà∂ËåÉÂõ¥
        servo2_min = self.servo_data['servo2'] - 400  # Ê∞¥Âπ≥ËàµÊú∫ÊúÄÂ∞èÂÄº
        servo2_max = self.servo_data['servo2'] + 400  # Ê∞¥Âπ≥ËàµÊú∫ÊúÄÂ§ßÂÄº
        servo1_min = self.servo_data['servo1'] - 200  # ÂûÇÁõ¥ËàµÊú∫ÊúÄÂ∞èÂÄº
        servo1_max = self.servo_data['servo1'] + 300  # ÂûÇÁõ¥ËàµÊú∫ÊúÄÂ§ßÂÄº
        
        # Ê∞¥Âπ≥Ë∑üÈöèÔºàËàµÊú∫2Ôºâ
        if abs(error_x) > follow_threshold_x:
            if error_x > 0:  # ÁõÆÊ†áÂú®Âè≥ËæπÔºåÂ§¥ÂêëÂè≥ËΩ¨
                new_x_dis = self.x_dis + servo_step_x
            else:  # ÁõÆÊ†áÂú®Â∑¶ËæπÔºåÂ§¥ÂêëÂ∑¶ËΩ¨
                new_x_dis = self.x_dis - servo_step_x
            
            # ÈôêÂà∂ËàµÊú∫ËåÉÂõ¥
            new_x_dis = max(servo2_min, min(servo2_max, new_x_dis))
            
            if new_x_dis != self.x_dis:
                self.x_dis = new_x_dis
                Board.setPWMServoPulse(2, self.x_dis, 20)
                print(f"üîÑ Â§¥ÈÉ®Ê∞¥Âπ≥Ë∑üÈöè: {self.x_dis}, ÁõÆÊ†áX: {target_x}, ËØØÂ∑Æ: {error_x}")
        
        # ÂûÇÁõ¥Ë∑üÈöèÔºàËàµÊú∫1Ôºâ
        if abs(error_y) > follow_threshold_y:
            if error_y > 0:  # ÁõÆÊ†áÂú®‰∏ãÊñπÔºåÂ§¥Âêë‰∏ã
                new_y_dis = self.y_dis + servo_step_y
            else:  # ÁõÆÊ†áÂú®‰∏äÊñπÔºåÂ§¥Âêë‰∏ä
                new_y_dis = self.y_dis - servo_step_y
            
            # ÈôêÂà∂ËàµÊú∫ËåÉÂõ¥
            new_y_dis = max(servo1_min, min(servo1_max, new_y_dis))
            
            if new_y_dis != self.y_dis:
                self.y_dis = new_y_dis
                Board.setPWMServoPulse(1, self.y_dis, 20)
                print(f"üîÑ Â§¥ÈÉ®ÂûÇÁõ¥Ë∑üÈöè: {self.y_dis}, ÁõÆÊ†áY: {target_y}, ËØØÂ∑Æ: {error_y}")
    
    def search_for_object(self):
        """ÊêúÁ¥¢ÁõÆÊ†áÁâ©‰ΩìÔºàÊîπËøõÊêúÁ¥¢ÈÄªËæëÔºâ"""
        if self.start_count:
            self.start_count = False
            self.time_start = time.time()
            print("üîç ÂºÄÂßãÊêúÁ¥¢ÁõÆÊ†áÁâ©‰Ωì...")
        else:
            if time.time() - self.time_start > 0.5:
                if 0 < self.servo_data['servo2'] - self.x_dis <= abs(self.d_x) and self.d_y > 0:
                    print("üîÑ ÊêúÁ¥¢ÂÆåÊàêÔºåÊú∫Âô®‰∫∫ËΩ¨‰ΩìÂØªÊâæÁõÆÊ†á")
                    self.x_dis = self.servo_data['servo2']
                    self.y_dis = self.servo_data['servo1']
                    Board.setPWMServoPulse(1, self.y_dis, 20)
                    Board.setPWMServoPulse(2, self.x_dis, 20)
                    AGC.runActionGroup(self.turn_right, times=5, lock_servos=self.lock_servos)
                elif self.head_turn == 'left_right':
                    # Ê∞¥Âπ≥ÊêúÁ¥¢
                    self.x_dis += self.d_x
                    print(f"üîç Ê∞¥Âπ≥ÊêúÁ¥¢: {self.x_dis}")
                    if self.x_dis > self.servo_data['servo2'] + 400 or self.x_dis < self.servo_data['servo2'] - 400:
                        self.head_turn = 'up_down'
                        self.d_x = -self.d_x
                        print("üîÑ ÂàáÊç¢Âà∞ÂûÇÁõ¥ÊêúÁ¥¢")
                elif self.head_turn == 'up_down':
                    # ÂûÇÁõ¥ÊêúÁ¥¢
                    self.y_dis += self.d_y
                    print(f"üîç ÂûÇÁõ¥ÊêúÁ¥¢: {self.y_dis}")
                    if self.y_dis > self.servo_data['servo1'] + 300 or self.y_dis < self.servo_data['servo1']:
                        self.head_turn = 'left_right'
                        self.d_y = -self.d_y
                        print("üîÑ ÂàáÊç¢Âà∞Ê∞¥Âπ≥ÊêúÁ¥¢")
                
                Board.setPWMServoPulse(1, self.y_dis, 20)
                Board.setPWMServoPulse(2, self.x_dis, 20)
                time.sleep(0.02)
    
    def process_frame(self, img):
        """Â§ÑÁêÜËßÜÈ¢ëÂ∏ß"""
        if not self.is_running or self.stop_detect:
            if self.step == 5:
                self.object_center_x = 0
            elif self.step == 6:
                self.find_box = not self.find_box
                self.object_center_x = -2
                self.step = 1
                self.stop_detect = False
            return img
        
        if not self.current_object_color:
            self.object_center_x = -4
            return img
        
        # È¢úËâ≤Ê£ÄÊµã
        color, self.color_center_x, self.color_center_y, color_angle = self.color_detect(img, self.current_object_color)
        
        # Ê†πÊçÆÈò∂ÊÆµÁ°ÆÂÆöÁõÆÊ†á
        if self.find_box:  # Êê¨ËøêÈò∂ÊÆµ - ÊâæÊñπÂùó
            self.object_center_x, self.object_center_y, self.object_angle = self.color_center_x, self.color_center_y, color_angle
        else:  # ÊîæÁΩÆÈò∂ÊÆµ - ÊâæÊ†áÁ≠æ
            tag_data = self.apriltag_detect(img)
            
            target_tag_id = self.color_tag[self.current_object_color]
            if tag_data[target_tag_id - 1][0] != -1:  # ÊâæÂà∞ÁõÆÊ†áÊ†áÁ≠æ
                self.object_center_x, self.object_center_y, self.object_angle = tag_data[target_tag_id - 1]
            else:  # ÈÄöËøáÂÖ∂‰ªñÊ†áÁ≠æÂà§Êñ≠‰ΩçÁΩÆ
                self.turn = self.get_turn_direction(target_tag_id, tag_data)
                if self.turn == 'None':
                    self.object_center_x, self.object_center_y, self.object_angle = -1, -1, 0
                else:
                    self.object_center_x, self.object_center_y, self.object_angle = -3, -1, 0
        
        return img
    
    def start_transport(self, color):
        """ÂºÄÂßãÊê¨ËøêÊåáÂÆöÈ¢úËâ≤ÁöÑÊñπÂùóÔºàÂ¢ûÂº∫Â§¥ÈÉ®ÂàùÂßãÂåñÔºâ"""
        if color not in self.color_tag:
            return False
        
        self.current_object_color = color
        self.is_running = True
        self.reset_transport_vars()
        
        # ÂàùÂßãÂåñÂ§¥ÈÉ®‰ΩçÁΩÆ
        self.init_head_position()
        
        print(f"üöõ ÂºÄÂßãÊê¨Ëøê‰ªªÂä°: {self.color_names_chinese[color]}")
        return True
    
    def init_head_position(self):
        """ÂàùÂßãÂåñÂ§¥ÈÉ®‰ΩçÁΩÆ"""
        try:
            print("üîÑ ÂàùÂßãÂåñÊú∫Âô®‰∫∫Â§¥ÈÉ®‰ΩçÁΩÆ...")
            # ËÆæÁΩÆÂ§¥ÈÉ®Âà∞‰∏≠ÂøÉ‰ΩçÁΩÆ
            Board.setPWMServoPulse(1, self.servo_data['servo1'], 500)  # ÂûÇÁõ¥ËàµÊú∫
            Board.setPWMServoPulse(2, self.servo_data['servo2'], 500)  # Ê∞¥Âπ≥ËàµÊú∫
            time.sleep(1)  # Á≠âÂæÖËàµÊú∫Âà∞‰Ωç
            
            # Êõ¥Êñ∞ÂΩìÂâç‰ΩçÁΩÆËÆ∞ÂΩï
            self.x_dis = self.servo_data['servo2']
            self.y_dis = self.servo_data['servo1']
            
            print(f"‚úÖ Â§¥ÈÉ®ÂàùÂßãÂåñÂÆåÊàê: Ê∞¥Âπ≥={self.x_dis}, ÂûÇÁõ¥={self.y_dis}")
        except Exception as e:
            print(f"‚ùå Â§¥ÈÉ®ÂàùÂßãÂåñÂ§±Ë¥•: {e}")
    
    def process_frame(self, img):
        """Â§ÑÁêÜËßÜÈ¢ëÂ∏ßÔºàÂ¢ûÂº∫ÊòæÁ§∫‰ø°ÊÅØÔºâ"""
        if not self.is_running or self.stop_detect:
            if self.step == 5:
                self.object_center_x = 0
            elif self.step == 6:
                self.find_box = not self.find_box
                self.object_center_x = -2
                self.step = 1
                self.stop_detect = False
            return img
        
        if not self.current_object_color:
            self.object_center_x = -4
            return img
        
        # È¢úËâ≤Ê£ÄÊµã
        color, self.color_center_x, self.color_center_y, color_angle = self.color_detect(img, self.current_object_color)
        
        # Ê†πÊçÆÈò∂ÊÆµÁ°ÆÂÆöÁõÆÊ†á
        if self.find_box:  # Êê¨ËøêÈò∂ÊÆµ - ÊâæÊñπÂùó
            self.object_center_x, self.object_center_y, self.object_angle = self.color_center_x, self.color_center_y, color_angle
        else:  # ÊîæÁΩÆÈò∂ÊÆµ - ÊâæÊ†áÁ≠æ
            tag_data = self.apriltag_detect(img)
            
            target_tag_id = self.color_tag[self.current_object_color]
            if tag_data[target_tag_id - 1][0] != -1:  # ÊâæÂà∞ÁõÆÊ†áÊ†áÁ≠æ
                self.object_center_x, self.object_center_y, self.object_angle = tag_data[target_tag_id - 1]
            else:  # ÈÄöËøáÂÖ∂‰ªñÊ†áÁ≠æÂà§Êñ≠‰ΩçÁΩÆ
                self.turn = self.get_turn_direction(target_tag_id, tag_data)
                if self.turn == 'None':
                    self.object_center_x, self.object_center_y, self.object_angle = -1, -1, 0
                else:
                    self.object_center_x, self.object_center_y, self.object_angle = -3, -1, 0
        
        # Âú®ÂõæÂÉè‰∏äÁªòÂà∂Ë∑üË∏™‰ø°ÊÅØ
        self.draw_tracking_info(img)
        
        return img
    
    def draw_tracking_info(self, img):
        """Âú®ÂõæÂÉè‰∏äÁªòÂà∂Ë∑üË∏™‰ø°ÊÅØ"""
        # ÁªòÂà∂ÂõæÂÉè‰∏≠ÂøÉÁÇπ
        img_center_x, img_center_y = 320, 240
        cv2.circle(img, (img_center_x, img_center_y), 10, (0, 0, 255), 2)
        cv2.putText(img, 'CENTER', (img_center_x-30, img_center_y-15), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1)
        
        # ÁªòÂà∂ÁõÆÊ†á‰ΩçÁΩÆ
        if self.object_center_x > 0 and self.object_center_y > 0:
            cv2.circle(img, (self.object_center_x, self.object_center_y), 8, (0, 255, 0), -1)
            cv2.putText(img, 'TARGET', (self.object_center_x-30, self.object_center_y-15), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)
            
            # ÁªòÂà∂ÂÅèÂ∑ÆÁ∫ø
            cv2.line(img, (img_center_x, img_center_y), 
                    (self.object_center_x, self.object_center_y), (255, 255, 0), 2)
            
            # ÊòæÁ§∫ÂÅèÂ∑ÆÂÄº
            error_x = self.object_center_x - img_center_x
            error_y = self.object_center_y - img_center_y
            cv2.putText(img, f'Error: ({error_x:.0f}, {error_y:.0f})', 
                       (10, img.shape[0] - 50), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 0), 2)
        
        # ÊòæÁ§∫Â§¥ÈÉ®‰ΩçÁΩÆ‰ø°ÊÅØ
        cv2.putText(img, f'Head: H={self.x_dis}, V={self.y_dis}', 
                   (10, img.shape[0] - 20), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
    
    def stop_transport(self):
        """ÂÅúÊ≠¢Êê¨Ëøê"""
        self.is_running = False
        self.current_object_color = None
        print("‚èπÔ∏è Êê¨Ëøê‰ªªÂä°Â∑≤ÂÅúÊ≠¢")

class EnhancedCameraManager:
    """Â¢ûÂº∫ÁöÑÊëÑÂÉèÂ§¥ÁÆ°ÁêÜÂô®"""
    
    def __init__(self):
        self.camera = None
        self.camera_type = None
        self.frame_count = 0
        self.last_frame_time = time.time()
        self.fps = 0
        
    def initialize_camera(self):
        print("üîÑ ÂàùÂßãÂåñÊëÑÂÉèÂ§¥...")
        
        # Â∞ùËØïHiWonderÊëÑÂÉèÂ§¥
        if CAMERA_AVAILABLE:
            try:
                self.camera = Camera.Camera()
                self.camera.camera_open()
                time.sleep(2)
                frame = self.camera.frame
                if frame is not None and frame.size > 0:
                    self.camera_type = 'HiWonder'
                    print("‚úÖ HiWonderÊëÑÂÉèÂ§¥ÂàùÂßãÂåñÊàêÂäü")
                    return True
            except Exception as e:
                print(f"‚ùå HiWonderÊëÑÂÉèÂ§¥ÂàùÂßãÂåñÂ§±Ë¥•: {e}")
        
        # Â∞ùËØïUSBÊëÑÂÉèÂ§¥
        for i in range(3):
            try:
                camera = cv2.VideoCapture(i)
                if camera.isOpened():
                    ret, frame = camera.read()
                    if ret and frame is not None:
                        self.camera = camera
                        self.camera_type = f'USB_{i}'
                        print(f"‚úÖ USBÊëÑÂÉèÂ§¥{i}ÂàùÂßãÂåñÊàêÂäü")
                        return True
                camera.release()
            except Exception as e:
                print(f"‚ùå USBÊëÑÂÉèÂ§¥{i}Â§±Ë¥•: {e}")
        
        print("‚ùå ÊâÄÊúâÊëÑÂÉèÂ§¥ÂàùÂßãÂåñÂ§±Ë¥•")
        return False
    
    def read_frame(self):
        if self.camera is None:
            return False, None
        
        try:
            if self.camera_type == 'HiWonder':
                frame = self.camera.frame
                ret = frame is not None and frame.size > 0
            else:
                ret, frame = self.camera.read()
            
            if ret and frame is not None:
                self.frame_count += 1
                current_time = time.time()
                if current_time - self.last_frame_time >= 1.0:
                    self.fps = self.frame_count / (current_time - self.last_frame_time)
                    self.frame_count = 0
                    self.last_frame_time = current_time
                
                return True, frame
            else:
                return False, None
                
        except Exception as e:
            print(f"‚ùå ÊëÑÂÉèÂ§¥ËØªÂèñÈîôËØØ: {e}")
            return False, None
    
    def close(self):
        if self.camera:
            try:
                if self.camera_type == 'HiWonder' and hasattr(self.camera, 'camera_close'):
                    self.camera.camera_close()
                else:
                    self.camera.release()
                print(f"‚úÖ ÊëÑÂÉèÂ§¥Â∑≤ÂÖ≥Èó≠")
            except Exception as e:
                print(f"‚ùå ÊëÑÂÉèÂ§¥ÂÖ≥Èó≠Â§±Ë¥•: {e}")

class VoiceControlSystem:
    """ÂÆåÊï¥ÁöÑËØ≠Èü≥ÊéßÂà∂Á≥ªÁªüÔºàÂàÜÊ≠•Êê¨ËøêÊ®°ÂºèÔºâ"""
    
    def __init__(self):
        print("üöÄ ÂàùÂßãÂåñTonyPiÂÆåÊï¥ËØ≠Èü≥ÊéßÂà∂Á≥ªÁªü...")
        
        # ÂàùÂßãÂåñÊëÑÂÉèÂ§¥ÁÆ°ÁêÜÂô®
        self.camera_manager = EnhancedCameraManager()
        self.camera_available = self.camera_manager.initialize_camera()
        
        # ÂàùÂßãÂåñÊ£ÄÊµãÂô®
        self.color_detector = SimpleColorDetector()
        self.face_detector = OriginalFaceDetector()
        self.tag_detector = AprilTagDetector()
        
        # ÂàùÂßãÂåñÊê¨ËøêÁ≥ªÁªü
        self.transport_system = TransportSystem(voice_callback=self.speak)
        
        # ÂàùÂßãÂåñTTSÔºàÂàÜÁ¶ªÈîôËØØÂ§ÑÁêÜÔºâ
        self.tts_available = False
        if TTS_AVAILABLE:
            try:
                self.tts = TTS.TTS()
                self.tts.TTSModuleSpeak('[h0][v10][m3]', 'TTSÊµãËØï')
                self.tts_available = True
                print("‚úÖ TTSÂàùÂßãÂåñÂíåÊµãËØïÊàêÂäü")
            except Exception as e:
                print(f"‚ùå TTSÂàùÂßãÂåñÂ§±Ë¥•: {e}")
        
        # ÂàùÂßãÂåñASRÔºà‰ºòÂÖàÔºâ- ‰øÆÊîπËØ≠Èü≥ÂëΩ‰ª§ÈÖçÁΩÆ
        self.asr_available = False
        if ASR_AVAILABLE:
            try:
                self.asr = ASR.ASR()
                # ÈÖçÁΩÆËØ≠Èü≥ÂëΩ‰ª§ - ‰øÆÊîπ‰∏∫ÂàÜÊ≠•Êìç‰Ωú
                self.asr.eraseWords()
                self.asr.setMode(2)
                self.asr.addWords(1, 'kai shi')              # ÂºÄÂßã/ÊøÄÊ¥ª
                self.asr.addWords(2, 'ban yun')              # Êê¨ËøêÔºàËøõÂÖ•Êê¨ËøêÊ®°ÂºèÔºâ
                self.asr.addWords(3, 'hong se')              # Á∫¢Ëâ≤
                self.asr.addWords(4, 'lv se')                # ÁªøËâ≤
                self.asr.addWords(5, 'lan se')               # ËìùËâ≤
                self.asr.addWords(6, 'ting zhi')             # ÂÅúÊ≠¢
                self.asr.addWords(7, 'tui chu')              # ÈÄÄÂá∫
                self.asr.addWords(8, 'ren lian shi bie')     # ‰∫∫ËÑ∏ËØÜÂà´
                self.asr.addWords(9, 'yan se shi bie')       # È¢úËâ≤ËØÜÂà´
                self.asr.addWords(10, 'biao qian shi bie')   # Ê†áÁ≠æËØÜÂà´
                self.asr_available = True
                print("‚úÖ ASRÁ≥ªÁªüÂàùÂßãÂåñÊàêÂäüÔºàÂàÜÊ≠•Êê¨ËøêÊ®°ÂºèÔºâ")
            except Exception as e:
                print(f"‚ùå ASRÂàùÂßãÂåñÂ§±Ë¥•: {e}")
        
        # ËÆæÁΩÆÊ£ÄÊµãÂô®ÁöÑËØ≠Èü≥ÂõûË∞É
        self.color_detector.set_voice_callback(self.speak)
        self.face_detector.set_voice_callback(self.speak)
        self.tag_detector.set_voice_callback(self.speak)
        
        # ÂàùÂßãÂåñVoskÔºàÂ§áÁî®ËØ≠Èü≥ËØÜÂà´Ôºâ- ‰øÆÊîπÂëΩ‰ª§Êò†Â∞Ñ
        self.vosk_available = False
        if VOSK_AVAILABLE:
            try:
                self.vosk_recognizer = VoskVoiceRecognizer()
                if self.vosk_recognizer.start_listening():
                    self.vosk_available = True
                    print("‚úÖ VoskËØ≠Èü≥ËØÜÂà´ÂàùÂßãÂåñÊàêÂäü")
            except Exception as e:
                print(f"‚ùå VoskÂàùÂßãÂåñÂ§±Ë¥•: {e}")
        
        # ÂàùÂßãÂåñÊú∫Âô®‰∫∫
        if ACTION_CONTROL_AVAILABLE:
            try:
                print("ü§ñ ÂàùÂßãÂåñÊú∫Âô®‰∫∫Âä®‰Ωú...")
                AGC.runActionGroup('stand')
                
                # ÂàùÂßãÂåñÊú∫Âô®‰∫∫Â§¥ÈÉ®‰ΩçÁΩÆ
                print("üîÑ ÂàùÂßãÂåñÊú∫Âô®‰∫∫Â§¥ÈÉ®‰ΩçÁΩÆ...")
                try:
                    servo_data = yaml_handle.get_yaml_data(yaml_handle.servo_file_path) if yaml_handle else {'servo1': 1500, 'servo2': 1500}
                    Board.setPWMServoPulse(1, servo_data['servo1'], 500)  # ÂûÇÁõ¥ËàµÊú∫
                    Board.setPWMServoPulse(2, servo_data['servo2'], 500)  # Ê∞¥Âπ≥ËàµÊú∫
                    time.sleep(1)
                    print(f"‚úÖ Â§¥ÈÉ®ÂàùÂßãÂåñÂÆåÊàê: Ê∞¥Âπ≥={servo_data['servo2']}, ÂûÇÁõ¥={servo_data['servo1']}")
                except Exception as e:
                    print(f"‚ùå Â§¥ÈÉ®ÂàùÂßãÂåñÂ§±Ë¥•: {e}")
                
                print("‚úÖ Êú∫Âô®‰∫∫ÂàùÂßãÂåñÂÆåÊàê")
            except Exception as e:
                print(f"‚ùå Êú∫Âô®‰∫∫ÂàùÂßãÂåñÂ§±Ë¥•: {e}")
        
        # Á≥ªÁªüÁä∂ÊÄÅÁÆ°ÁêÜ
        self.current_mode = "ÂæÖÊú∫"
        self.transport_ready = False  # Êê¨ËøêÂáÜÂ§áÁä∂ÊÄÅ
        self.is_running = True
        self.vision_thread = None
        self.headless_mode = os.environ.get('DISPLAY') is None
        
        # ÊòæÁ§∫ÂäüËÉΩÂèØÁî®ÊÄß
        print(f"\nüìã ÂäüËÉΩÊ®°ÂùóÁä∂ÊÄÅ:")
        print(f"   È¢úËâ≤ËØÜÂà´: ‚úÖ Â§áÁî®Ê£ÄÊµãÂô®")
        print(f"   ‰∫∫ËÑ∏ËØÜÂà´: ‚úÖ ÂÆåÊï¥ÈÄªËæëÊ£ÄÊµãÂô®")
        print(f"   Ê†áÁ≠æËØÜÂà´: {'‚úÖ AprilTag' if APRILTAG_AVAILABLE else '‚ùå'}")
        print(f"   Êê¨ËøêÂäüËÉΩ: ‚úÖ ÂàÜÊ≠•Êê¨ËøêÁ≥ªÁªü")
        print(f"   ËØ≠Èü≥ËØÜÂà´: {'‚úÖ ASR' if self.asr_available else ''} {'‚úÖ Vosk' if self.vosk_available else ''}")
        print(f"   ËØ≠Èü≥ÂêàÊàê: {'‚úÖ' if self.tts_available else '‚ùå'}")
        print(f"   Âä®‰ΩúÊéßÂà∂: {'‚úÖ' if ACTION_CONTROL_AVAILABLE else '‚ùå'}")
        print(f"   ÊëÑÂÉèÂ§¥: {'‚úÖ' if self.camera_available else '‚ùå'}")
        
        print("‚úÖ ÂÆåÊï¥ËØ≠Èü≥ÊéßÂà∂Á≥ªÁªüÂàùÂßãÂåñÂÆåÊàêÔºàÂàÜÊ≠•Êê¨ËøêÊ®°ÂºèÔºâ")
    
    def speak(self, text):
        """ËØ≠Èü≥Êí≠Êä•ÂáΩÊï∞"""
        print(f"üîä ËØ≠Èü≥Êí≠Êä•: {text}")
        
        if self.tts_available:
            try:
                self.tts.TTSModuleSpeak('[h0][v10][m3]', text)
                return True
            except Exception as e:
                print(f"‚ùå TTSÊí≠Êä•Â§±Ë¥•: {e}")
        
        print(f"üí¨ [Ê®°ÊãüËØ≠Èü≥] {text}")
        return False
    
    def process_voice_commands(self):
        """Â§ÑÁêÜËØ≠Èü≥ÂëΩ‰ª§"""
        # Â§ÑÁêÜASRÂëΩ‰ª§Ôºà‰ºòÂÖàÔºâ
        if self.asr_available:
            try:
                command = self.asr.getResult()
                if command:
                    self.handle_asr_command(command)
            except Exception as e:
                print(f"‚ùå ASRÂëΩ‰ª§Â§ÑÁêÜÈîôËØØ: {e}")
        
        # Â§ÑÁêÜVoskÂëΩ‰ª§ÔºàÂ§áÁî®Ôºâ
        if self.vosk_available:
            try:
                command = self.vosk_recognizer.get_result()
                if command:
                    self.handle_vosk_command(command)
            except Exception as e:
                print(f"‚ùå VoskÂëΩ‰ª§Â§ÑÁêÜÈîôËØØ: {e}")
    
    def handle_asr_command(self, command):
        """Â§ÑÁêÜASRËØ≠Èü≥ÂëΩ‰ª§ÔºàÂàÜÊ≠•Êê¨ËøêÈÄªËæëÔºâ"""
        print(f"üéØ ASRÂëΩ‰ª§: {command}")
        
        if command == 1:  # ÂºÄÂßã/ÊøÄÊ¥ª
            self.speak('Á≥ªÁªüÊøÄÊ¥ª')
            
        elif command == 2:  # Êê¨ËøêÔºàËøõÂÖ•Êê¨ËøêÊ®°ÂºèÔºâ
            self.enter_transport_mode()
            
        elif command == 3:  # Á∫¢Ëâ≤
            if self.transport_ready:
                self.start_transport_with_color('red')
            elif self.current_mode == "È¢úËâ≤ËØÜÂà´":
                self.color_detector.set_target_color('red')
                self.speak("ÂàáÊç¢Âà∞Á∫¢Ëâ≤Ê£ÄÊµã")
            else:
                self.speak("ËØ∑ÂÖàËØ¥Êê¨Ëøê")
                
        elif command == 4:  # ÁªøËâ≤
            if self.transport_ready:
                self.start_transport_with_color('green')
            elif self.current_mode == "È¢úËâ≤ËØÜÂà´":
                self.color_detector.set_target_color('green')
                self.speak("ÂàáÊç¢Âà∞ÁªøËâ≤Ê£ÄÊµã")
            else:
                self.speak("ËØ∑ÂÖàËØ¥Êê¨Ëøê")
                
        elif command == 5:  # ËìùËâ≤
            if self.transport_ready:
                self.start_transport_with_color('blue')
            elif self.current_mode == "È¢úËâ≤ËØÜÂà´":
                self.color_detector.set_target_color('blue')
                self.speak("ÂàáÊç¢Âà∞ËìùËâ≤Ê£ÄÊµã")
            else:
                self.speak("ËØ∑ÂÖàËØ¥Êê¨Ëøê")
                
        elif command == 6:  # ÂÅúÊ≠¢
            self.stop_current_mode()
            
        elif command == 7:  # ÈÄÄÂá∫
            self.shutdown_system()
            
        elif command == 8:  # ‰∫∫ËÑ∏ËØÜÂà´
            self.start_face_detection()
            
        elif command == 9:  # È¢úËâ≤ËØÜÂà´
            self.start_color_recognition()
            
        elif command == 10:  # Ê†áÁ≠æËØÜÂà´
            self.start_tag_detection()
    
    def handle_vosk_command(self, command):
        """Â§ÑÁêÜVoskËØ≠Èü≥ÂëΩ‰ª§ÔºàÂàÜÊ≠•Êê¨ËøêÈÄªËæëÔºâ"""
        print(f"üéØ VoskÂëΩ‰ª§: {command}")
        
        if command == 1:  # È¢úËâ≤ËØÜÂà´
            self.start_color_recognition()
        elif command == 2:  # ‰∫∫ËÑ∏ËØÜÂà´
            self.start_face_detection()
        elif command == 3:  # Ê†áÁ≠æËØÜÂà´
            self.start_tag_detection()
        elif command == 20:  # Êê¨ËøêÊ®°Âºè
            self.enter_transport_mode()
        elif 11 <= command <= 14:  # È¢úËâ≤Êåá‰ª§
            color_map = {11: 'red', 12: 'green', 13: 'blue', 14: 'yellow'}
            color_chinese_map = {11: 'Á∫¢Ëâ≤', 12: 'ÁªøËâ≤', 13: 'ËìùËâ≤', 14: 'ÈªÑËâ≤'}
            
            if command in color_map:
                color = color_map[command]
                color_chinese = color_chinese_map[command]
                
                if self.transport_ready:
                    # Âú®Êê¨ËøêÊ®°Âºè‰∏ãÔºåÊâßË°åÊê¨Ëøê
                    if color in ['red', 'green', 'blue']:  # Âè™ÊîØÊåÅRGBÊê¨Ëøê
                        self.start_transport_with_color(color)
                    else:
                        self.speak("Êê¨ËøêÊ®°Âºè‰∏çÊîØÊåÅÈªÑËâ≤")
                elif self.current_mode == "È¢úËâ≤ËØÜÂà´":
                    # Âú®È¢úËâ≤ËØÜÂà´Ê®°Âºè‰∏ãÔºåÂàáÊç¢Ê£ÄÊµãÈ¢úËâ≤
                    if self.color_detector.set_target_color(color):
                        self.speak(f"ÂàáÊç¢Âà∞{color_chinese}Ê£ÄÊµã")
                else:
                    # ÂÖ∂‰ªñÊÉÖÂÜµÊèêÁ§∫ÂÖàËøõÂÖ•ÂØπÂ∫îÊ®°Âºè
                    self.speak("ËØ∑ÂÖàËøõÂÖ•Êê¨ËøêÊ®°ÂºèÊàñÈ¢úËâ≤ËØÜÂà´Ê®°Âºè")
                    
        elif command == 4:  # ÂÅúÊ≠¢
            self.stop_current_mode()
        elif command == 5:  # ÈÄÄÂá∫
            self.shutdown_system()
        elif command == 9:  # Êå•ÊâãÊµãËØï
            self.test_face_action()
    
    def enter_transport_mode(self):
        """ËøõÂÖ•Êê¨ËøêÂáÜÂ§áÊ®°Âºè"""
        if not self.camera_available:
            self.speak("ÊëÑÂÉèÂ§¥‰∏çÂèØÁî®")
            return
            
        self.stop_current_mode()
        self.transport_ready = True
        self.current_mode = "Êê¨ËøêÂáÜÂ§á"
        
        print("üöõ ËøõÂÖ•Êê¨ËøêÂáÜÂ§áÊ®°Âºè")
        self.speak("ËøõÂÖ•Êê¨ËøêÊ®°ÂºèÔºåËØ∑ËØ¥Ë¶ÅÊê¨ËøêÁöÑÈ¢úËâ≤ÔºöÁ∫¢Ëâ≤„ÄÅÁªøËâ≤ÊàñËìùËâ≤")
        
        # ÂêØÂä®Êê¨ËøêÂáÜÂ§áÁïåÈù¢
        self.vision_thread = threading.Thread(target=self.transport_ready_loop)
        self.vision_thread.daemon = True
        self.vision_thread.start()
    
    def start_transport_with_color(self, color):
        """‰ΩøÁî®ÊåáÂÆöÈ¢úËâ≤ÂºÄÂßãÊê¨Ëøê"""
        if not self.transport_ready:
            self.speak("ËØ∑ÂÖàËØ¥Êê¨ËøêËøõÂÖ•Êê¨ËøêÊ®°Âºè")
            return
            
        self.transport_ready = False
        self.current_mode = "Êê¨ËøêÊâßË°å"
        
        color_chinese = self.transport_system.color_names_chinese[color]
        print(f"üöõ ÂºÄÂßãÊâßË°åÊê¨Ëøê: {color_chinese}")
        self.speak(f"ÂºÄÂßãÊê¨Ëøê{color_chinese}ÊñπÂùó")
        
        if self.transport_system.start_transport(color):
            # ÈáçÊñ∞ÂêØÂä®Á∫øÁ®ãËøõÂÖ•ÊâßË°åÊ®°Âºè
            if self.vision_thread and self.vision_thread.is_alive():
                pass  # Á∫øÁ®ã‰ºöËá™Âä®ÂàáÊç¢Âà∞ÊâßË°åÊ®°Âºè
        else:
            self.speak("Êê¨ËøêÂêØÂä®Â§±Ë¥•")
            self.transport_ready = True
            self.current_mode = "Êê¨ËøêÂáÜÂ§á"
    
    def transport_ready_loop(self):
        """Êê¨ËøêÂáÜÂ§áÊ®°ÂºèÂæ™ÁéØ"""
        print("üöõ Êê¨ËøêÂáÜÂ§áÊ®°ÂºèËøêË°å‰∏≠...")
        
        frame_count = 0
        last_status_time = time.time()
        
        while self.current_mode in ["Êê¨ËøêÂáÜÂ§á", "Êê¨ËøêÊâßË°å"] and self.is_running:
            try:
                ret, img = self.camera_manager.read_frame()
                if ret and img is not None:
                    frame_count += 1
                    
                    # Â∫îÁî®Áï∏ÂèòÁü´Ê≠£ÔºàÂ¶ÇÊûúÂèØÁî®Ôºâ
                    if CALIBRATION_AVAILABLE:
                        img = cv2.remap(img, mapx, mapy, cv2.INTER_LINEAR)
                    
                    if self.current_mode == "Êê¨ËøêÂáÜÂ§á":
                        # Êê¨ËøêÂáÜÂ§áÁä∂ÊÄÅ - ÊòæÁ§∫Á≠âÂæÖÁïåÈù¢
                        cv2.putText(img, 'Transport Mode Ready', (10, 30), 
                                   cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)
                        cv2.putText(img, 'Say color: Red, Green, Blue', (10, 70), 
                                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)
                        cv2.putText(img, 'Frame: {}'.format(frame_count), (10, 100), 
                                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
                        
                        if self.headless_mode:
                            current_time = time.time()
                            if current_time - last_status_time >= 5.0:
                                print("üöõ Êê¨ËøêÂáÜÂ§áÁä∂ÊÄÅ: Á≠âÂæÖÈ¢úËâ≤Êåá‰ª§")
                                print("   ÂèØËØ¥ÔºöÁ∫¢Ëâ≤„ÄÅÁªøËâ≤„ÄÅËìùËâ≤")
                                last_status_time = current_time
                        else:
                            cv2.imshow('Transport System', img)
                            key = cv2.waitKey(1) & 0xFF
                            if key == 27:  # ESC
                                break
                            elif key == ord('1'):  # Á∫¢Ëâ≤
                                self.start_transport_with_color('red')
                            elif key == ord('2'):  # ÁªøËâ≤
                                self.start_transport_with_color('green')
                            elif key == ord('3'):  # ËìùËâ≤
                                self.start_transport_with_color('blue')
                            elif key == ord('s'):  # ÂÅúÊ≠¢
                                self.stop_current_mode()
                                
                    elif self.current_mode == "Êê¨ËøêÊâßË°å":
                        # Êê¨ËøêÊâßË°åÁä∂ÊÄÅ - Â§ÑÁêÜÊê¨ËøêÈÄªËæë
                        result_frame = self.transport_system.process_frame(img)
                        
                        # Ê∑ªÂä†Êê¨ËøêÁä∂ÊÄÅÊòæÁ§∫
                        stage = "Êê¨ËøêÈò∂ÊÆµ" if self.transport_system.find_box else "ÊîæÁΩÆÈò∂ÊÆµ"
                        if self.transport_system.current_object_color:
                            color_chinese = self.transport_system.color_names_chinese[self.transport_system.current_object_color]
                            cv2.putText(result_frame, f'{stage}: {color_chinese}', (10, 30), 
                                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
                            cv2.putText(result_frame, f'Step: {self.transport_system.step}', (10, 60), 
                                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)
                        
                        # Ê£ÄÊü•Êê¨ËøêÊòØÂê¶ÂÆåÊàê
                        if not self.transport_system.current_object_color and not self.transport_system.is_running:
                            print("üöõ Êê¨Ëøê‰ªªÂä°ÂÆåÊàêÔºåËøîÂõûÂáÜÂ§áÊ®°Âºè")
                            self.transport_ready = True
                            self.current_mode = "Êê¨ËøêÂáÜÂ§á"
                            self.speak("Êê¨ËøêÂÆåÊàêÔºåÂèØÁªßÁª≠ËØ¥È¢úËâ≤ËøõË°å‰∏ã‰∏ÄÊ¨°Êê¨Ëøê")
                        
                        if self.headless_mode:
                            current_time = time.time()
                            if current_time - last_status_time >= 3.0:
                                print(f"üöõ Êê¨ËøêÁä∂ÊÄÅ: {stage}")
                                if self.transport_system.current_object_color:
                                    print(f"   ÁõÆÊ†áÈ¢úËâ≤: {color_chinese}")
                                    print(f"   Ê≠•È™§: {self.transport_system.step}")
                                last_status_time = current_time
                        else:
                            cv2.imshow('Transport System', result_frame)
                            key = cv2.waitKey(1) & 0xFF
                            if key == 27:  # ESC
                                break
                            elif key == ord('s'):  # ÂÅúÊ≠¢
                                self.stop_current_mode()
                else:
                    print("‚ùå Êó†Ê≥ïËØªÂèñÊëÑÂÉèÂ§¥ÂõæÂÉè")
                    time.sleep(0.1)
                    
            except Exception as e:
                print(f"‚ùå Êê¨ËøêÂæ™ÁéØÈîôËØØ: {e}")
                time.sleep(0.1)
        
        if not self.headless_mode:
            cv2.destroyWindow('Transport System')
        print("üöõ Êê¨ËøêÊ®°ÂºèÁªìÊùü")
    
    def test_face_action(self):
        """ÊµãËØï‰∫∫ËÑ∏Âä®‰Ωú"""
        print("üß™ === Áõ¥Êé•ÊµãËØï‰∫∫ËÑ∏Âä®‰Ωú ===")
        self.speak("ÂºÄÂßãÊµãËØï‰∫∫ËÑ∏Âä®‰Ωú")
        self.face_detector.test_action()
    
    def start_color_recognition(self):
        """ÂêØÂä®È¢úËâ≤ËØÜÂà´"""
        if not self.camera_available:
            self.speak("ÊëÑÂÉèÂ§¥‰∏çÂèØÁî®")
            return
            
        if self.current_mode == "È¢úËâ≤ËØÜÂà´":
            self.speak("Â∑≤Âú®È¢úËâ≤ËØÜÂà´Ê®°Âºè")
            return
            
        self.stop_current_mode()
        self.current_mode = "È¢úËâ≤ËØÜÂà´"
        print("üé® ÂêØÂä®È¢úËâ≤ËØÜÂà´")
        self.speak("ÂºÄÂßãÈ¢úËâ≤ËØÜÂà´ÔºåÂèØËØ¥Á∫¢Ëâ≤„ÄÅÁªøËâ≤„ÄÅËìùËâ≤„ÄÅÈªÑËâ≤ÂàáÊç¢Ê£ÄÊµãÁõÆÊ†á")
        
        self.vision_thread = threading.Thread(target=self.color_recognition_loop)
        self.vision_thread.daemon = True
        self.vision_thread.start()
    
    def start_face_detection(self):
        """ÂêØÂä®‰∫∫ËÑ∏ËØÜÂà´"""
        if not self.camera_available:
            self.speak("ÊëÑÂÉèÂ§¥‰∏çÂèØÁî®")
            return
            
        if self.current_mode == "‰∫∫ËÑ∏ËØÜÂà´":
            self.speak("Â∑≤Âú®‰∫∫ËÑ∏ËØÜÂà´Ê®°Âºè")
            return
            
        self.stop_current_mode()
        self.current_mode = "‰∫∫ËÑ∏ËØÜÂà´"
        print("üë§ ÂêØÂä®‰∫∫ËÑ∏ËØÜÂà´")
        self.speak("ÂºÄÂßã‰∫∫ËÑ∏ËØÜÂà´")
        
        self.face_detector.start_detection()
        
        self.vision_thread = threading.Thread(target=self.face_detection_loop)
        self.vision_thread.daemon = True
        self.vision_thread.start()
    
    def start_tag_detection(self):
        """ÂêØÂä®Ê†áÁ≠æËØÜÂà´"""
        if not self.camera_available:
            self.speak("ÊëÑÂÉèÂ§¥‰∏çÂèØÁî®")
            return
            
        if self.current_mode == "Ê†áÁ≠æËØÜÂà´":
            self.speak("Â∑≤Âú®Ê†áÁ≠æËØÜÂà´Ê®°Âºè")
            return
            
        self.stop_current_mode()
        self.current_mode = "Ê†áÁ≠æËØÜÂà´"
        print("üè∑Ô∏è  ÂêØÂä®Ê†áÁ≠æËØÜÂà´")
        self.speak("ÂºÄÂßãÊ†áÁ≠æËØÜÂà´")
        
        self.vision_thread = threading.Thread(target=self.tag_detection_loop)
        self.vision_thread.daemon = True
        self.vision_thread.start()
    
    def color_recognition_loop(self):
        """È¢úËâ≤ËØÜÂà´Âæ™ÁéØ"""
        print("üé® È¢úËâ≤ËØÜÂà´ËøêË°å‰∏≠...")
        
        frame_count = 0
        last_status_time = time.time()
        
        while self.current_mode == "È¢úËâ≤ËØÜÂà´" and self.is_running:
            try:
                ret, img = self.camera_manager.read_frame()
                if ret and img is not None:
                    frame_count += 1
                    
                    result_frame = self.color_detector.detect_color(img)
                    
                    if result_frame is not None:
                        if self.headless_mode:
                            current_time = time.time()
                            if current_time - last_status_time >= 5.0:
                                color_chinese = self.color_detector.color_names_chinese.get(
                                    self.color_detector.current_target_color, 
                                    self.color_detector.current_target_color)
                                print(f"üé® È¢úËâ≤ËØÜÂà´Áä∂ÊÄÅ: Ê£ÄÊµã{color_chinese}")
                                last_status_time = current_time
                        else:
                            cv2.imshow('Color Recognition', result_frame)
                            key = cv2.waitKey(1) & 0xFF
                            if key == 27:  # ESC
                                break
                            elif key == ord('1'):  # Á∫¢Ëâ≤
                                self.color_detector.set_target_color('red')
                                self.speak("ÂàáÊç¢Âà∞Á∫¢Ëâ≤Ê£ÄÊµã")
                            elif key == ord('2'):  # ÁªøËâ≤
                                self.color_detector.set_target_color('green')
                                self.speak("ÂàáÊç¢Âà∞ÁªøËâ≤Ê£ÄÊµã")
                            elif key == ord('3'):  # ËìùËâ≤
                                self.color_detector.set_target_color('blue')
                                self.speak("ÂàáÊç¢Âà∞ËìùËâ≤Ê£ÄÊµã")
                            elif key == ord('4'):  # ÈªÑËâ≤
                                self.color_detector.set_target_color('yellow')
                                self.speak("ÂàáÊç¢Âà∞ÈªÑËâ≤Ê£ÄÊµã")
                else:
                    print("‚ùå Êó†Ê≥ïËØªÂèñÊëÑÂÉèÂ§¥ÂõæÂÉè")
                    time.sleep(0.1)
                    
            except Exception as e:
                print(f"‚ùå È¢úËâ≤ËØÜÂà´ÈîôËØØ: {e}")
                time.sleep(0.1)
        
        if not self.headless_mode:
            cv2.destroyWindow('Color Recognition')
        print("üé® È¢úËâ≤ËØÜÂà´ÁªìÊùü")
    
    def face_detection_loop(self):
        """‰∫∫ËÑ∏ËØÜÂà´Âæ™ÁéØ"""
        print("üë§ ‰∫∫ËÑ∏ËØÜÂà´ËøêË°å‰∏≠...")
        
        frame_count = 0
        last_status_time = time.time()
        
        while self.current_mode == "‰∫∫ËÑ∏ËØÜÂà´" and self.is_running:
            try:
                ret, img = self.camera_manager.read_frame()
                if ret and img is not None:
                    frame_count += 1
                    
                    result_frame = self.face_detector.detect_faces(img)
                    
                    if result_frame is not None:
                        if self.headless_mode:
                            current_time = time.time()
                            if current_time - last_status_time >= 3.0:
                                print(f"üë§ ‰∫∫ËÑ∏ËØÜÂà´Áä∂ÊÄÅ: ËøêË°å‰∏≠")
                                last_status_time = current_time
                        else:
                            cv2.imshow('Face Detection', result_frame)
                            key = cv2.waitKey(1) & 0xFF
                            if key == 27:  # ESC
                                break
                            elif key == ord('t'):  # ÊåâTÊµãËØïÂä®‰Ωú
                                self.face_detector.test_action()
                else:
                    print("‚ùå Êó†Ê≥ïËØªÂèñÊëÑÂÉèÂ§¥ÂõæÂÉè")
                    time.sleep(0.1)
                    
            except Exception as e:
                print(f"‚ùå ‰∫∫ËÑ∏ËØÜÂà´ÈîôËØØ: {e}")
                time.sleep(0.1)
        
        if not self.headless_mode:
            cv2.destroyWindow('Face Detection')
        
        self.face_detector.stop_detection()
        print("üë§ ‰∫∫ËÑ∏ËØÜÂà´ÁªìÊùü")
    
    def tag_detection_loop(self):
        """Ê†áÁ≠æËØÜÂà´Âæ™ÁéØ"""
        print("üè∑Ô∏è  Ê†áÁ≠æËØÜÂà´ËøêË°å‰∏≠...")
        
        frame_count = 0
        last_status_time = time.time()
        
        while self.current_mode == "Ê†áÁ≠æËØÜÂà´" and self.is_running:
            try:
                ret, img = self.camera_manager.read_frame()
                if ret and img is not None:
                    frame_count += 1
                    
                    result_frame = self.tag_detector.detect_tags(img)
                        
                    if result_frame is not None:
                        if self.headless_mode:
                            current_time = time.time()
                            if current_time - last_status_time >= 3.0:
                                print(f"üè∑Ô∏è  Ê†áÁ≠æËØÜÂà´Áä∂ÊÄÅ: ËøêË°å‰∏≠")
                                last_status_time = current_time
                        else:
                            cv2.imshow('Tag Detection', result_frame)
                            key = cv2.waitKey(1) & 0xFF
                            if key == 27:  # ESC
                                break
                else:
                    print("‚ùå Êó†Ê≥ïËØªÂèñÊëÑÂÉèÂ§¥ÂõæÂÉè")
                    time.sleep(0.1)
                    
            except Exception as e:
                print(f"‚ùå Ê†áÁ≠æËØÜÂà´ÈîôËØØ: {e}")
                time.sleep(0.1)
        
        if not self.headless_mode:
            cv2.destroyWindow('Tag Detection')
        print("üè∑Ô∏è  Ê†áÁ≠æËØÜÂà´ÁªìÊùü")
    
    def stop_current_mode(self):
        """ÂÅúÊ≠¢ÂΩìÂâçÊ®°Âºè"""
        if self.current_mode != "ÂæÖÊú∫":
            print(f"‚èπÔ∏è  ÂÅúÊ≠¢{self.current_mode}")
            self.speak(f"ÂÅúÊ≠¢{self.current_mode}")
            
            if self.current_mode == "‰∫∫ËÑ∏ËØÜÂà´":
                self.face_detector.stop_detection()
            elif self.current_mode in ["Êê¨ËøêÂáÜÂ§á", "Êê¨ËøêÊâßË°å"]:
                self.transport_system.stop_transport()
                self.transport_ready = False
            
            self.current_mode = "ÂæÖÊú∫"
    
    def shutdown_system(self):
        """ÂÖ≥Èó≠Á≥ªÁªü"""
        print("üîÑ ÂÖ≥Èó≠Á≥ªÁªü...")
        self.is_running = False
        self.transport_ready = False
        
        self.stop_current_mode()
        
        if self.camera_manager:
            self.camera_manager.close()
        
        if self.vosk_available:
            try:
                self.vosk_recognizer.stop_listening()
                print("‚úÖ VoskËØ≠Èü≥ËØÜÂà´Â∑≤ÂÅúÊ≠¢")
            except Exception as e:
                print(f"‚ùå VoskÂÅúÊ≠¢Â§±Ë¥•: {e}")
        
        if ACTION_CONTROL_AVAILABLE:
            try:
                AGC.runActionGroup('stand_slow')
                print("‚úÖ Êú∫Âô®‰∫∫Â§ç‰ΩçÂÆåÊàê")
            except Exception as e:
                print(f"‚ùå Êú∫Âô®‰∫∫Â§ç‰ΩçÂ§±Ë¥•: {e}")
        
        cv2.destroyAllWindows()
        self.speak('Á≥ªÁªüÂ∑≤ÂÖ≥Èó≠')
        print("‚úÖ Á≥ªÁªüÂ∑≤ÂÖ≥Èó≠")
    
    def run(self):
        """ËøêË°å‰∏ªÁ®ãÂ∫è"""
        print("="*70)
        print("üöÄ TonyPiÂÆåÊï¥ËØ≠Èü≥ÊéßÂà∂Á≥ªÁªüÂêØÂä®ÔºàÂàÜÊ≠•Êê¨ËøêÊ®°ÂºèÔºâ")
        print("="*70)
        
        print("\nüé§ ÊîØÊåÅÁöÑËØ≠Èü≥ÂëΩ‰ª§:")
        print("   üì¢ 'kai shi' - ÊøÄÊ¥ªÁ≥ªÁªü")
        print("   üöõ 'ban yun' - ËøõÂÖ•Êê¨ËøêÊ®°Âºè")
        print("   üî¥ 'hong se' - Á∫¢Ëâ≤ÔºàÊê¨ËøêÊ®°Âºè‰∏ãÊâßË°åÊê¨ËøêÁ∫¢Ëâ≤Ôºâ")
        print("   üü¢ 'lv se' - ÁªøËâ≤ÔºàÊê¨ËøêÊ®°Âºè‰∏ãÊâßË°åÊê¨ËøêÁªøËâ≤Ôºâ")
        print("   üîµ 'lan se' - ËìùËâ≤ÔºàÊê¨ËøêÊ®°Âºè‰∏ãÊâßË°åÊê¨ËøêËìùËâ≤Ôºâ")
        print("   üë§ 'ren lian shi bie' - ‰∫∫ËÑ∏ËØÜÂà´Ê®°Âºè")
        print("   üé® 'yan se shi bie' - È¢úËâ≤ËØÜÂà´Ê®°Âºè")
        print("   üè∑Ô∏è  'biao qian shi bie' - Ê†áÁ≠æËØÜÂà´Ê®°Âºè")
        print("   ‚èπÔ∏è  'ting zhi' - ÂÅúÊ≠¢ÂΩìÂâçÂäüËÉΩ")
        print("   üö™ 'tui chu' - ÈÄÄÂá∫Á≥ªÁªü")
        
        print("\nüéØ ‰ΩøÁî®ÊµÅÁ®ã:")
        print("   1Ô∏è‚É£  ËØ¥'Êê¨Ëøê' ‚Üí ËøõÂÖ•Êê¨ËøêÂáÜÂ§áÊ®°Âºè")
        print("   2Ô∏è‚É£  ËØ¥'Á∫¢Ëâ≤/ÁªøËâ≤/ËìùËâ≤' ‚Üí ÂºÄÂßãÊê¨ËøêÂØπÂ∫îÈ¢úËâ≤")
        print("   3Ô∏è‚É£  Êê¨ËøêÂÆåÊàêÂêéËá™Âä®ÂõûÂà∞ÂáÜÂ§áÊ®°ÂºèÔºåÂèØÁªßÁª≠Êê¨Ëøê")
        
        # Á≥ªÁªüÂ∞±Áª™ÊèêÁ§∫
        self.speak('ËØ≠Èü≥ÊéßÂà∂Á≥ªÁªüÂ∞±Áª™')
        
        try:
            while self.is_running:
                # Â§ÑÁêÜËØ≠Èü≥ÂëΩ‰ª§
                self.process_voice_commands()
                
                # ÈùûËßÜËßâÊ®°Âºè‰∏ãÁöÑÂü∫Êú¨Á≠âÂæÖ
                if self.current_mode == "ÂæÖÊú∫":
                    time.sleep(0.1)
                else:
                    time.sleep(0.01)
                    
        except KeyboardInterrupt:
            print("\nüëã Áî®Êà∑‰∏≠Êñ≠")
        except Exception as e:
            print(f"‚ùå Á≥ªÁªüËøêË°åÈîôËØØ: {e}")
        finally:
            self.shutdown_system()

# ÂÆåÊï¥ÁöÑVoskËØ≠Èü≥ËØÜÂà´Âô®Á±ª
class VoskVoiceRecognizer:
    def __init__(self, model_path="/home/pi/TonyPi/vosk-model-small-cn"):
        self.model_path = model_path
        self.is_listening = False
        self.audio_queue = queue.Queue()
        self.result_queue = queue.Queue()
        self.audio_stream = None
        self.recognizer = None
        self.model = None
        
        self.CHUNK = 4096
        self.FORMAT = pyaudio.paInt16
        self.CHANNELS = 1
        self.RATE = 16000
        
        # Êõ¥Êñ∞ÂëΩ‰ª§Êò†Â∞Ñ - ÂàÜÊ≠•Êê¨Ëøê
        self.command_map = {
            "È¢úËâ≤ËØÜÂà´": 1, "Ëâ≤ÂΩ©ËØÜÂà´": 1, "È¢úËâ≤Ê£ÄÊµã": 1, "ËØÜÂà´È¢úËâ≤": 1,
            "È¢úËâ≤": 1, "Ëâ≤ÂΩ©": 1, "Ê£ÄÊµãÈ¢úËâ≤": 1,
            
            "‰∫∫ËÑ∏ËØÜÂà´": 2, "Èù¢ÈÉ®ËØÜÂà´": 2, "ËÑ∏ÈÉ®Ê£ÄÊµã": 2, "‰∫∫ËÑ∏Ê£ÄÊµã": 2,
            "‰∫∫ËÑ∏": 2, "Èù¢ÈÉ®": 2, "ËÑ∏ÈÉ®": 2, "Ê£ÄÊµã‰∫∫ËÑ∏": 2,
            
            "Ê†áÁ≠æËØÜÂà´": 3, "tagËØÜÂà´": 3, "‰∫åÁª¥Á†Å": 3, "Êù°Á†ÅËØÜÂà´": 3,
            "Ê†áÁ≠æ": 3, "tag": 3,
            
            "Êê¨Ëøê": 20, "Êê¨ËøêÊ®°Âºè": 20, "ÂºÄÂßãÊê¨Ëøê": 20, "ËøõÂÖ•Êê¨Ëøê": 20,
            
            "Á∫¢Ëâ≤": 11, "ÁªøËâ≤": 12, "ËìùËâ≤": 13, "ÈªÑËâ≤": 14,
            "Á∫¢": 11, "Áªø": 12, "Ëìù": 13, "ÈªÑ": 14,
            
            "ÂÅúÊ≠¢": 4, "ÁªìÊùü": 4, "ÊöÇÂÅú": 4, "ÂÅú": 4,
            "ÈÄÄÂá∫": 5, "ÂÖ≥Èó≠": 5, "ÁªìÊùüÁ®ãÂ∫è": 5, "ÈÄÄ": 5, "ÂÖ≥": 5,
            
            "Áä∂ÊÄÅ": 6, "Â∏ÆÂä©": 7, "ÊµãËØï": 8, "Êå•Êâã": 9
        }
        
    def load_model(self):
        try:
            if not os.path.exists(self.model_path):
                print(f"‚ùå VoskÊ®°ÂûãË∑ØÂæÑ‰∏çÂ≠òÂú®: {self.model_path}")
                return False
                
            print("üîÑ Âä†ËΩΩVoskÊ®°Âûã...")
            self.model = vosk.Model(self.model_path)
            self.recognizer = vosk.KaldiRecognizer(self.model, self.RATE)
            print("‚úÖ VoskÊ®°ÂûãÂä†ËΩΩÊàêÂäü")
            return True
            
        except Exception as e:
            print(f"‚ùå Âä†ËΩΩVoskÊ®°ÂûãÂ§±Ë¥•: {e}")
            return False
    
    def init_audio(self):
        try:
            print("üé§ ÂàùÂßãÂåñÈü≥È¢ëËÆæÂ§á...")
            self.p = pyaudio.PyAudio()
            self.audio_stream = self.p.open(
                format=self.FORMAT,
                channels=self.CHANNELS,
                rate=self.RATE,
                input=True,
                frames_per_buffer=self.CHUNK,
                stream_callback=self._audio_callback
            )
            print("‚úÖ Èü≥È¢ëËÆæÂ§áÂàùÂßãÂåñÊàêÂäü")
            return True
        except Exception as e:
            print(f"‚ùå Èü≥È¢ëËÆæÂ§áÂàùÂßãÂåñÂ§±Ë¥•: {e}")
            return False
    
    def _audio_callback(self, in_data, frame_count, time_info, status):
        if self.is_listening:
            self.audio_queue.put(in_data)
        return (None, pyaudio.paContinue)
    
    def _recognition_thread(self):
        while self.is_listening:
            try:
                if not self.audio_queue.empty():
                    audio_data = self.audio_queue.get()
                    if self.recognizer.AcceptWaveform(audio_data):
                        result = json.loads(self.recognizer.Result())
                        text = result.get('text', '').strip()
                        if text:
                            print(f"üéØ ËØÜÂà´Âà∞ËØ≠Èü≥: '{text}'")
                            command_id = self._match_command(text)
                            if command_id:
                                print(f"‚úÖ ÂåπÈÖçÂà∞ÂëΩ‰ª§ID: {command_id}")
                                self.result_queue.put(command_id)
                            else:
                                print(f"‚ùì Êú™ÂåπÈÖçÂà∞ÂëΩ‰ª§")
                time.sleep(0.01)
            except Exception as e:
                print(f"‚ùå ËØ≠Èü≥ËØÜÂà´Á∫øÁ®ãÈîôËØØ: {e}")
                time.sleep(0.1)
    
    def _match_command(self, text):
        # ÂéüÂßãÊñáÊú¨ÂåπÈÖç
        for command, cmd_id in self.command_map.items():
            if command in text:
                return cmd_id
        
        # ÂéªÈô§Á©∫Ê†ºÂêéÂåπÈÖç
        text_no_space = re.sub(r'\s+', '', text)
        for command, cmd_id in self.command_map.items():
            command_no_space = re.sub(r'\s+', '', command)
            if command_no_space in text_no_space:
                return cmd_id
        
        # ÈÉ®ÂàÜÂÖ≥ÈîÆËØçÂåπÈÖç
        if "È¢úËâ≤" in text or "Ëâ≤ÂΩ©" in text:
            return 1
        elif "‰∫∫ËÑ∏" in text or "ËÑ∏" in text or "Èù¢ÈÉ®" in text:
            return 2
        elif "Ê†áÁ≠æ" in text or "tag" in text.lower():
            return 3
        elif "Êê¨Ëøê" in text:
            return 20
        elif "Á∫¢" in text:
            return 11
        elif "Áªø" in text:
            return 12
        elif "Ëìù" in text:
            return 13
        elif "ÈªÑ" in text:
            return 14
        elif "ÂÅú" in text or "ÁªìÊùü" in text:
            return 4
        elif "ÈÄÄ" in text or "ÂÖ≥" in text:
            return 5
        elif "Êå•Êâã" in text or "Êå•" in text:
            return 9
        
        return None
    
    def start_listening(self):
        if not VOSK_AVAILABLE:
            return False
        if not self.load_model():
            return False
        if not self.init_audio():
            return False
        
        self.is_listening = True
        self.audio_stream.start_stream()
        
        self.recognition_thread = threading.Thread(target=self._recognition_thread)
        self.recognition_thread.daemon = True
        self.recognition_thread.start()
        
        print("üé§ VoskËØ≠Èü≥ËØÜÂà´ÂºÄÂßãÁõëÂê¨...")
        return True
    
    def stop_listening(self):
        self.is_listening = False
        if self.audio_stream:
            self.audio_stream.stop_stream()
            self.audio_stream.close()
        if hasattr(self, 'p'):
            self.p.terminate()
    
    def get_result(self):
        if not self.result_queue.empty():
            return self.result_queue.get()
        return None

if __name__ == '__main__':
    # ÂàõÂª∫Âπ∂ËøêË°åÂÆåÊï¥ËØ≠Èü≥ÊéßÂà∂Á≥ªÁªüÔºàÂàÜÊ≠•Êê¨ËøêÊ®°ÂºèÔºâ
    system = VoiceControlSystem()
    system.run()